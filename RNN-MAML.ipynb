{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D0yhkRvX-uG"
      },
      "source": [
        "# **A Deep Learning Approach for Intrusion Detection Using Recurrent Neural Networks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qx_dyZdlSXMK"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import sklearn\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Utaaqng3NOY0",
        "outputId": "7ebad542-e716-49a6-8179-1912d2e1b911"
      },
      "outputs": [],
      "source": [
        "#training set\n",
        "df = pd.read_csv(\"/home/ids/NT114.O11.ATCL-IDS/Datasets/NSL-KDD/csv/KDDTrain+.csv\")\n",
        "#testing set\n",
        "df_test = pd.read_csv(\"/home/ids/NT114.O11.ATCL-IDS/Datasets/NSL-KDD/csv/KDDTest+.csv\")\n",
        "\n",
        "# Dropping redundant features\n",
        "df = df.drop(['r'], axis = 1)\n",
        "df_test = df_test.drop(['r'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_zKWRUDkWpiH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensions of the Training set: (125973, 42)\n",
            "Dimensions of the Test set: (22544, 42)\n"
          ]
        }
      ],
      "source": [
        "print('Dimensions of the Training set:',df.shape)\n",
        "print('Dimensions of the Test set:',df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAa8_nBFWwxf",
        "outputId": "6fbc146a-d156-4d7b-cd5c-2066e60317d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label distribution in the Training set:\n",
            "****************************************\n",
            "normal             67343\n",
            "neptune            41214\n",
            "satan               3633\n",
            "ipsweep             3599\n",
            "portsweep           2931\n",
            "smurf               2646\n",
            "nmap                1493\n",
            "back                 956\n",
            "teardrop             892\n",
            "warezclient          890\n",
            "pod                  201\n",
            "guess_passwd          53\n",
            "buffer_overflow       30\n",
            "warezmaster           20\n",
            "land                  18\n",
            "imap                  11\n",
            "rootkit               10\n",
            "loadmodule             9\n",
            "ftp_write              8\n",
            "multihop               7\n",
            "phf                    4\n",
            "perl                   3\n",
            "spy                    2\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Label distribution in the Training set:')\n",
        "print(\"****************************************\")\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KZnGhf0-qk-",
        "outputId": "35c7f7cd-afae-46c4-985c-017c6a8f513e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label distribution in the Test set:\n",
            "**************************************\n",
            "normal             9711\n",
            "neptune            4657\n",
            "guess_passwd       1231\n",
            "mscan               996\n",
            "warezmaster         944\n",
            "apache2             737\n",
            "satan               735\n",
            "processtable        685\n",
            "smurf               665\n",
            "back                359\n",
            "snmpguess           331\n",
            "saint               319\n",
            "mailbomb            293\n",
            "snmpgetattack       178\n",
            "portsweep           157\n",
            "ipsweep             141\n",
            "httptunnel          133\n",
            "nmap                 73\n",
            "pod                  41\n",
            "buffer_overflow      20\n",
            "multihop             18\n",
            "named                17\n",
            "ps                   15\n",
            "sendmail             14\n",
            "rootkit              13\n",
            "xterm                13\n",
            "teardrop             12\n",
            "xlock                 9\n",
            "land                  7\n",
            "xsnoop                4\n",
            "ftp_write             3\n",
            "worm                  2\n",
            "loadmodule            2\n",
            "perl                  2\n",
            "sqlattack             2\n",
            "udpstorm              2\n",
            "phf                   2\n",
            "imap                  1\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Label distribution in the Test set:')\n",
        "print(\"**************************************\")\n",
        "print(df_test['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFUPOfTWW7jF"
      },
      "source": [
        "# **Data preprocessing:**\n",
        "\n",
        "One-Hot-Encoding is used to convert all categorical properties to binary properties. One-Hot-Endcoding requirement, the input to this transformer must be an integer matrix expressing values taken with categorical (discrete) properties. The output will be a sparse matrix in which each column corresponds to a possible value. It is assumed that the input properties have values in the range [0, n_values]. Therefore, to convert each category to a number, properties must first be converted with LabelEncoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyLnY-XCXVnk",
        "outputId": "64cf1a8a-ffc3-4ae6-ae35-e5348f7bf0bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set:\n",
            "Feature 'protocol_type' has 3 categories\n",
            "Feature 'service' has 70 categories\n",
            "Feature 'flag' has 11 categories\n",
            "Feature 'label' has 23 categories\n",
            "\n",
            "Distribution of categories in service:\n",
            "http        40338\n",
            "private     21853\n",
            "domain_u     9043\n",
            "smtp         7313\n",
            "ftp_data     6860\n",
            "Name: service, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# columns are categorical, not yet binary: protocol_type (column 2), service (column 3), flag (column 4).\n",
        "\n",
        "print('Training set:')\n",
        "for col_name in df.columns:\n",
        "    if df[col_name].dtypes == 'object' :\n",
        "        unique_cat = len(df[col_name].unique())\n",
        "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
        "\n",
        "print()\n",
        "print('Distribution of categories in service:')\n",
        "print(df['service'].value_counts().sort_values(ascending=False).head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhKXNXlwXb5G",
        "outputId": "8908be6a-58b4-4163-ab6f-a85adc6bdfb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set:\n",
            "Feature 'protocol_type' has 3 categories\n",
            "Feature 'service' has 64 categories\n",
            "Feature 'flag' has 11 categories\n",
            "Feature 'label' has 38 categories\n"
          ]
        }
      ],
      "source": [
        "# Test set\n",
        "print('Test set:')\n",
        "for col_name in df_test.columns:\n",
        "    if df_test[col_name].dtypes == 'object' :\n",
        "        unique_cat = len(df_test[col_name].unique())\n",
        "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZKviPW0XnzU"
      },
      "source": [
        "**LabelEncoder**\n",
        "\n",
        "**Insert categorical features into a 2D numpy array**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "SYmvn2qWXxs2",
        "outputId": "65645719-3383-4ea6-d74f-899a1be12885"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp_data</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>udp</td>\n",
              "      <td>other</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tcp</td>\n",
              "      <td>private</td>\n",
              "      <td>S0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  protocol_type   service flag\n",
              "0           tcp  ftp_data   SF\n",
              "1           udp     other   SF\n",
              "2           tcp   private   S0\n",
              "3           tcp      http   SF\n",
              "4           tcp      http   SF"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "categorical_columns=['protocol_type', 'service', 'flag']\n",
        "\n",
        "df_categorical_values = df[categorical_columns]\n",
        "testdf_categorical_values = df_test[categorical_columns]\n",
        "\n",
        "df_categorical_values.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNVa7mN9X1qV",
        "outputId": "9512f269-550e-41d8-8342-1509c5bb0c4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Protocol_type_icmp', 'Protocol_type_tcp', 'Protocol_type_udp']\n",
            "['service_IRC', 'service_X11', 'service_Z39_50', 'service_aol', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_harvest', 'service_hostnames', 'service_http', 'service_http_2784', 'service_http_443', 'service_http_8001', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_red_i', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tftp_u', 'service_tim_i', 'service_time', 'service_urh_i', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois']\n",
            "['flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH']\n"
          ]
        }
      ],
      "source": [
        "# protocol type\n",
        "unique_protocol=sorted(df.protocol_type.unique())\n",
        "string1 = 'Protocol_type_'\n",
        "unique_protocol2=[string1 + x for x in unique_protocol]\n",
        "print(unique_protocol2)\n",
        "\n",
        "# service\n",
        "unique_service=sorted(df.service.unique())\n",
        "string2 = 'service_'\n",
        "unique_service2=[string2 + x for x in unique_service]\n",
        "print(unique_service2)\n",
        "\n",
        "\n",
        "# flag\n",
        "unique_flag=sorted(df.flag.unique())\n",
        "string3 = 'flag_'\n",
        "unique_flag2=[string3 + x for x in unique_flag]\n",
        "print(unique_flag2)\n",
        "\n",
        "\n",
        "# put together\n",
        "dumcols=unique_protocol2 + unique_service2 + unique_flag2\n",
        "\n",
        "\n",
        "#do it for test set\n",
        "unique_service_test=sorted(df_test.service.unique())\n",
        "unique_service2_test=[string2 + x for x in unique_service_test]\n",
        "testdumcols=unique_protocol2 + unique_service2_test + unique_flag2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf-QhZyfX9Jd"
      },
      "source": [
        "**Transform categorical features into numbers using LabelEncoder()**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta0CsfRUX5Tg",
        "outputId": "bebffb0b-9faa-4085-a2aa-b6008f8a680a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  protocol_type   service flag\n",
            "0           tcp  ftp_data   SF\n",
            "1           udp     other   SF\n",
            "2           tcp   private   S0\n",
            "3           tcp      http   SF\n",
            "4           tcp      http   SF\n",
            "--------------------\n",
            "   protocol_type  service  flag\n",
            "0              1       20     9\n",
            "1              2       44     9\n",
            "2              1       49     5\n",
            "3              1       24     9\n",
            "4              1       24     9\n"
          ]
        }
      ],
      "source": [
        "# train set\n",
        "df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\n",
        "print(df_categorical_values.head())\n",
        "print('--------------------')\n",
        "print(df_categorical_values_enc.head())\n",
        "# test set\n",
        "testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq_pnkScYDOi"
      },
      "source": [
        "**One-Hot-Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MVBytj5dYGDu"
      },
      "outputs": [],
      "source": [
        "# train set\n",
        "enc = OneHotEncoder(categories='auto')\n",
        "df_categorical_values_encenc = enc.fit_transform(df_categorical_values_enc)\n",
        "df_cat_data = pd.DataFrame(df_categorical_values_encenc.toarray(),columns=dumcols)\n",
        "# test set\n",
        "testdf_categorical_values_encenc = enc.fit_transform(testdf_categorical_values_enc)\n",
        "testdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(),columns=testdumcols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D-ZvKY6bS-r"
      },
      "source": [
        "Missing columns in test set are added \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxTdPirkbW-V",
        "outputId": "95d9b31d-1b85-4567-aff4-520309a29ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(125973, 84)\n",
            "(22544, 84)\n"
          ]
        }
      ],
      "source": [
        "trainservice=df['service'].tolist()\n",
        "testservice= df_test['service'].tolist()\n",
        "difference=list(set(trainservice) - set(testservice))\n",
        "string = 'service_'\n",
        "difference=[string + x for x in difference]\n",
        "\n",
        "for col in difference:\n",
        "    testdf_cat_data[col] = 0\n",
        "\n",
        "print(df_cat_data.shape)    \n",
        "print(testdf_cat_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vsl_YcrcSd8"
      },
      "source": [
        "New numeric columns are added to main dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOXgIdAZcVAF",
        "outputId": "ba9284bb-abd9-4f12-977f-a0f8ce03bde7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(125973, 123)\n",
            "(22544, 123)\n"
          ]
        }
      ],
      "source": [
        "newdf=df.join(df_cat_data)\n",
        "newdf.drop('flag', axis=1, inplace=True)\n",
        "newdf.drop('protocol_type', axis=1, inplace=True)\n",
        "newdf.drop('service', axis=1, inplace=True)\n",
        "\n",
        "# test data\n",
        "newdf_test=df_test.join(testdf_cat_data)\n",
        "newdf_test.drop('flag', axis=1, inplace=True)\n",
        "newdf_test.drop('protocol_type', axis=1, inplace=True)\n",
        "newdf_test.drop('service', axis=1, inplace=True)\n",
        "\n",
        "print(newdf.shape)\n",
        "print(newdf_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CYtoG2TWK-Lj"
      },
      "outputs": [],
      "source": [
        "# Convert the \"label\" catagorical values into numerical values\n",
        "\n",
        "labeldf=newdf['label']\n",
        "labeldf_test=newdf_test['label']\n",
        "\n",
        "# change the label column\n",
        "newlabeldf=labeldf.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
        "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
        "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
        "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
        "newlabeldf_test=labeldf_test.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
        "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
        "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
        "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "N34KiIHrNCrg"
      },
      "outputs": [],
      "source": [
        "# put the new label column back\n",
        "newdf['label'] = newlabeldf\n",
        "newdf_test['label'] = newlabeldf_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "z1FyTUMWBG7J",
        "outputId": "aaf55518-40a5-41ab-b1c3-1a4672ca4718"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_RSTO</th>\n",
              "      <th>flag_RSTOS0</th>\n",
              "      <th>flag_RSTR</th>\n",
              "      <th>flag_S0</th>\n",
              "      <th>flag_S1</th>\n",
              "      <th>flag_S2</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>491</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>232</td>\n",
              "      <td>8153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>199</td>\n",
              "      <td>420</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125968</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125969</th>\n",
              "      <td>8</td>\n",
              "      <td>105</td>\n",
              "      <td>145</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125970</th>\n",
              "      <td>0</td>\n",
              "      <td>2231</td>\n",
              "      <td>384</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125971</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125972</th>\n",
              "      <td>0</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>125973 rows Ã— 123 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
              "0              0        491          0     0               0       0    0   \n",
              "1              0        146          0     0               0       0    0   \n",
              "2              0          0          0     0               0       0    0   \n",
              "3              0        232       8153     0               0       0    0   \n",
              "4              0        199        420     0               0       0    0   \n",
              "...          ...        ...        ...   ...             ...     ...  ...   \n",
              "125968         0          0          0     0               0       0    0   \n",
              "125969         8        105        145     0               0       0    0   \n",
              "125970         0       2231        384     0               0       0    0   \n",
              "125971         0          0          0     0               0       0    0   \n",
              "125972         0        151          0     0               0       0    0   \n",
              "\n",
              "        num_failed_logins  logged_in  num_compromised  ...  flag_RSTO  \\\n",
              "0                       0          0                0  ...        0.0   \n",
              "1                       0          0                0  ...        0.0   \n",
              "2                       0          0                0  ...        0.0   \n",
              "3                       0          1                0  ...        0.0   \n",
              "4                       0          1                0  ...        0.0   \n",
              "...                   ...        ...              ...  ...        ...   \n",
              "125968                  0          0                0  ...        0.0   \n",
              "125969                  0          0                0  ...        0.0   \n",
              "125970                  0          1                0  ...        0.0   \n",
              "125971                  0          0                0  ...        0.0   \n",
              "125972                  0          1                0  ...        0.0   \n",
              "\n",
              "        flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
              "0               0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
              "1               0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
              "2               0.0        0.0      1.0      0.0      0.0      0.0      0.0   \n",
              "3               0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
              "4               0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
              "...             ...        ...      ...      ...      ...      ...      ...   \n",
              "125968          0.0        0.0      1.0      0.0      0.0      0.0      0.0   \n",
              "125969          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
              "125970          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
              "125971          0.0        0.0      1.0      0.0      0.0      0.0      0.0   \n",
              "125972          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
              "\n",
              "        flag_SH  class  \n",
              "0           0.0      0  \n",
              "1           0.0      0  \n",
              "2           0.0      1  \n",
              "3           0.0      0  \n",
              "4           0.0      0  \n",
              "...         ...    ...  \n",
              "125968      0.0      1  \n",
              "125969      0.0      0  \n",
              "125970      0.0      0  \n",
              "125971      0.0      1  \n",
              "125972      0.0      0  \n",
              "\n",
              "[125973 rows x 123 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Convert \"label\" into normal=0 and attack=1 for KDDTrain+\n",
        "newdf['class']=newdf['label'].apply(lambda x: 1 if x>=1 else 0)\n",
        "newdf.drop(['label'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "jsLea3rLOZNv",
        "outputId": "f66d1952-cabf-4e30-bdff-ca3e36e7d5bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ids/.local/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>service_red_i</th>\n",
              "      <th>service_harvest</th>\n",
              "      <th>service_aol</th>\n",
              "      <th>service_http_8001</th>\n",
              "      <th>service_urh_i</th>\n",
              "      <th>service_http_2784</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>12983</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22539</th>\n",
              "      <td>0</td>\n",
              "      <td>794</td>\n",
              "      <td>333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22540</th>\n",
              "      <td>0</td>\n",
              "      <td>317</td>\n",
              "      <td>938</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22541</th>\n",
              "      <td>0</td>\n",
              "      <td>54540</td>\n",
              "      <td>8314</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22542</th>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22543</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22544 rows Ã— 123 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
              "0             0          0          0     0               0       0    0   \n",
              "1             0          0          0     0               0       0    0   \n",
              "2             2      12983          0     0               0       0    0   \n",
              "3             0         20          0     0               0       0    0   \n",
              "4             1          0         15     0               0       0    0   \n",
              "...         ...        ...        ...   ...             ...     ...  ...   \n",
              "22539         0        794        333     0               0       0    0   \n",
              "22540         0        317        938     0               0       0    0   \n",
              "22541         0      54540       8314     0               0       0    2   \n",
              "22542         0         42         42     0               0       0    0   \n",
              "22543         0          0          0     0               0       0    0   \n",
              "\n",
              "       num_failed_logins  logged_in  num_compromised  ...  flag_S3  flag_SF  \\\n",
              "0                      0          0                0  ...      0.0      0.0   \n",
              "1                      0          0                0  ...      0.0      0.0   \n",
              "2                      0          0                0  ...      0.0      1.0   \n",
              "3                      0          0                0  ...      0.0      1.0   \n",
              "4                      0          0                0  ...      0.0      0.0   \n",
              "...                  ...        ...              ...  ...      ...      ...   \n",
              "22539                  0          1                0  ...      0.0      1.0   \n",
              "22540                  0          1                0  ...      0.0      1.0   \n",
              "22541                  0          1                1  ...      0.0      1.0   \n",
              "22542                  0          0                0  ...      0.0      1.0   \n",
              "22543                  0          0                0  ...      0.0      0.0   \n",
              "\n",
              "       flag_SH  service_red_i  service_harvest  service_aol  \\\n",
              "0          0.0              0                0            0   \n",
              "1          0.0              0                0            0   \n",
              "2          0.0              0                0            0   \n",
              "3          0.0              0                0            0   \n",
              "4          0.0              0                0            0   \n",
              "...        ...            ...              ...          ...   \n",
              "22539      0.0              0                0            0   \n",
              "22540      0.0              0                0            0   \n",
              "22541      0.0              0                0            0   \n",
              "22542      0.0              0                0            0   \n",
              "22543      0.0              0                0            0   \n",
              "\n",
              "       service_http_8001  service_urh_i  service_http_2784  class  \n",
              "0                      0              0                  0      1  \n",
              "1                      0              0                  0      1  \n",
              "2                      0              0                  0      0  \n",
              "3                      0              0                  0      1  \n",
              "4                      0              0                  0      1  \n",
              "...                  ...            ...                ...    ...  \n",
              "22539                  0              0                  0      0  \n",
              "22540                  0              0                  0      0  \n",
              "22541                  0              0                  0      1  \n",
              "22542                  0              0                  0      0  \n",
              "22543                  0              0                  0      1  \n",
              "\n",
              "[22544 rows x 123 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Convert \"label\" into normal=0 and attack=1 for KDDTest+\n",
        "newdf_test['class']=newdf_test['label'].apply(lambda x: 1 if x>=1 else 0)\n",
        "newdf_test.drop(['label'],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "rsD_WWwHTZ4c",
        "outputId": "bdff8201-2f0a-4a45-f2c1-60e2872de840"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_REJ</th>\n",
              "      <th>flag_RSTO</th>\n",
              "      <th>flag_RSTOS0</th>\n",
              "      <th>flag_RSTR</th>\n",
              "      <th>flag_S0</th>\n",
              "      <th>flag_S1</th>\n",
              "      <th>flag_S2</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>...</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "      <td>67343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>...</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "      <td>58630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows Ã— 123 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       duration  src_bytes  dst_bytes   land  wrong_fragment  urgent    hot  \\\n",
              "class                                                                         \n",
              "0         67343      67343      67343  67343           67343   67343  67343   \n",
              "1         58630      58630      58630  58630           58630   58630  58630   \n",
              "\n",
              "       num_failed_logins  logged_in  num_compromised  ...  flag_REJ  \\\n",
              "class                                                 ...             \n",
              "0                  67343      67343            67343  ...     67343   \n",
              "1                  58630      58630            58630  ...     58630   \n",
              "\n",
              "       flag_RSTO  flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  \\\n",
              "class                                                                          \n",
              "0          67343        67343      67343    67343    67343    67343    67343   \n",
              "1          58630        58630      58630    58630    58630    58630    58630   \n",
              "\n",
              "       flag_SF  flag_SH  \n",
              "class                    \n",
              "0        67343    67343  \n",
              "1        58630    58630  \n",
              "\n",
              "[2 rows x 123 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newdf.groupby('class').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "moHBVhIxWinZ",
        "outputId": "7f628706-ce35-407a-8629-31c45606d059"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "sns.countplot(x=\"class\", data=newdf, palette=\"Accent\")\n",
        "plt.title('Class Distributions in KDDTrain+ \\n 0: Normal || 1: Attack', fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "Rs1HFr_NUAxi",
        "outputId": "6586770d-01ea-428b-9811-62f933c92da6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_S2</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>service_red_i</th>\n",
              "      <th>service_harvest</th>\n",
              "      <th>service_aol</th>\n",
              "      <th>service_http_8001</th>\n",
              "      <th>service_urh_i</th>\n",
              "      <th>service_http_2784</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>...</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "      <td>9711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>...</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "      <td>12833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows Ã— 123 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       duration  src_bytes  dst_bytes   land  wrong_fragment  urgent    hot  \\\n",
              "class                                                                         \n",
              "0          9711       9711       9711   9711            9711    9711   9711   \n",
              "1         12833      12833      12833  12833           12833   12833  12833   \n",
              "\n",
              "       num_failed_logins  logged_in  num_compromised  ...  flag_S2  flag_S3  \\\n",
              "class                                                 ...                     \n",
              "0                   9711       9711             9711  ...     9711     9711   \n",
              "1                  12833      12833            12833  ...    12833    12833   \n",
              "\n",
              "       flag_SF  flag_SH  service_red_i  service_harvest  service_aol  \\\n",
              "class                                                                  \n",
              "0         9711     9711           9711             9711         9711   \n",
              "1        12833    12833          12833            12833        12833   \n",
              "\n",
              "       service_http_8001  service_urh_i  service_http_2784  \n",
              "class                                                       \n",
              "0                   9711           9711               9711  \n",
              "1                  12833          12833              12833  \n",
              "\n",
              "[2 rows x 123 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newdf_test.groupby('class').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "lwB4O4sWVVO3",
        "outputId": "e4039186-0f8f-47a7-836a-4aadca270b99"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot(x=\"class\", data=newdf_test, palette=\"Accent\")\n",
        "plt.title('Class Distributions in KDDTest+ \\n 0: Normal || 1: Attack', fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRfv_qU7Ezdk"
      },
      "source": [
        "**Feature Scaling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__tRm4sRaVnm",
        "outputId": "c7ac3620-e399-4978-ecd0-b68c12b69a65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log2\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
            "0              0        491          0     0               0       0    0   \n",
            "1              0        146          0     0               0       0    0   \n",
            "2              0          0          0     0               0       0    0   \n",
            "3              0        232       8153     0               0       0    0   \n",
            "4              0        199        420     0               0       0    0   \n",
            "...          ...        ...        ...   ...             ...     ...  ...   \n",
            "125968         0          0          0     0               0       0    0   \n",
            "125969         8        105        145     0               0       0    0   \n",
            "125970         0       2231        384     0               0       0    0   \n",
            "125971         0          0          0     0               0       0    0   \n",
            "125972         0        151          0     0               0       0    0   \n",
            "\n",
            "        num_failed_logins  logged_in  num_compromised  ...  flag_RSTO  \\\n",
            "0                       0          0                0  ...        0.0   \n",
            "1                       0          0                0  ...        0.0   \n",
            "2                       0          0                0  ...        0.0   \n",
            "3                       0          1                0  ...        0.0   \n",
            "4                       0          1                0  ...        0.0   \n",
            "...                   ...        ...              ...  ...        ...   \n",
            "125968                  0          0                0  ...        0.0   \n",
            "125969                  0          0                0  ...        0.0   \n",
            "125970                  0          1                0  ...        0.0   \n",
            "125971                  0          0                0  ...        0.0   \n",
            "125972                  0          1                0  ...        0.0   \n",
            "\n",
            "        flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
            "0               0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
            "1               0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
            "2               0.0        0.0      1.0      0.0      0.0      0.0      0.0   \n",
            "3               0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
            "4               0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
            "...             ...        ...      ...      ...      ...      ...      ...   \n",
            "125968          0.0        0.0      1.0      0.0      0.0      0.0      0.0   \n",
            "125969          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
            "125970          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
            "125971          0.0        0.0      1.0      0.0      0.0      0.0      0.0   \n",
            "125972          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
            "\n",
            "        flag_SH  class  \n",
            "0           0.0      0  \n",
            "1           0.0      0  \n",
            "2           0.0      1  \n",
            "3           0.0      0  \n",
            "4           0.0      0  \n",
            "...         ...    ...  \n",
            "125968      0.0      1  \n",
            "125969      0.0      0  \n",
            "125970      0.0      0  \n",
            "125971      0.0      1  \n",
            "125972      0.0      0  \n",
            "\n",
            "[125973 rows x 124 columns]\n",
            "       duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
            "0             0          0          0     0               0       0    0   \n",
            "1             0          0          0     0               0       0    0   \n",
            "2             2      12983          0     0               0       0    0   \n",
            "3             0         20          0     0               0       0    0   \n",
            "4             1          0         15     0               0       0    0   \n",
            "...         ...        ...        ...   ...             ...     ...  ...   \n",
            "22539         0        794        333     0               0       0    0   \n",
            "22540         0        317        938     0               0       0    0   \n",
            "22541         0      54540       8314     0               0       0    2   \n",
            "22542         0         42         42     0               0       0    0   \n",
            "22543         0          0          0     0               0       0    0   \n",
            "\n",
            "       num_failed_logins  logged_in  num_compromised  ...  flag_S3  flag_SF  \\\n",
            "0                      0          0                0  ...      0.0      0.0   \n",
            "1                      0          0                0  ...      0.0      0.0   \n",
            "2                      0          0                0  ...      0.0      1.0   \n",
            "3                      0          0                0  ...      0.0      1.0   \n",
            "4                      0          0                0  ...      0.0      0.0   \n",
            "...                  ...        ...              ...  ...      ...      ...   \n",
            "22539                  0          1                0  ...      0.0      1.0   \n",
            "22540                  0          1                0  ...      0.0      1.0   \n",
            "22541                  0          1                1  ...      0.0      1.0   \n",
            "22542                  0          0                0  ...      0.0      1.0   \n",
            "22543                  0          0                0  ...      0.0      0.0   \n",
            "\n",
            "       flag_SH  service_red_i  service_harvest  service_aol  \\\n",
            "0          0.0              0                0            0   \n",
            "1          0.0              0                0            0   \n",
            "2          0.0              0                0            0   \n",
            "3          0.0              0                0            0   \n",
            "4          0.0              0                0            0   \n",
            "...        ...            ...              ...          ...   \n",
            "22539      0.0              0                0            0   \n",
            "22540      0.0              0                0            0   \n",
            "22541      0.0              0                0            0   \n",
            "22542      0.0              0                0            0   \n",
            "22543      0.0              0                0            0   \n",
            "\n",
            "       service_http_8001  service_urh_i  service_http_2784  class  \n",
            "0                      0              0                  0      1  \n",
            "1                      0              0                  0      1  \n",
            "2                      0              0                  0      0  \n",
            "3                      0              0                  0      1  \n",
            "4                      0              0                  0      1  \n",
            "...                  ...            ...                ...    ...  \n",
            "22539                  0              0                  0      0  \n",
            "22540                  0              0                  0      0  \n",
            "22541                  0              0                  0      1  \n",
            "22542                  0              0                  0      0  \n",
            "22543                  0              0                  0      1  \n",
            "\n",
            "[22544 rows x 124 columns]\n"
          ]
        }
      ],
      "source": [
        "# step1: apply the logarithmic scaling method for scaling to obtain the ranges of `duration[0,4.77]', `src_bytes[0,9.11]' and `dst_bytes[0,9.11]\n",
        "newdf['log2_value1'] = np.log2(newdf['duration'])\n",
        "newdf['log2_value2'] = np.log2(newdf['src_bytes'])\n",
        "newdf['log2_value3'] = np.log2(newdf['dst_bytes'])\n",
        "newdf=newdf.drop(['log2_value3','log2_value2','log2_value1'], axis=1)\n",
        "\n",
        "\n",
        "# testing set\n",
        "\n",
        "newdf_test['log2_value1'] = np.log2(newdf_test['duration'])\n",
        "newdf_test['log2_value2'] = np.log2(newdf_test['src_bytes'])\n",
        "newdf_test['log2_value3'] = np.log2(newdf_test['dst_bytes'])\n",
        "newdf_test=newdf_test.drop(['log2_value3','log2_value2','log2_value1'], axis=1)\n",
        "\n",
        "print(newdf)\n",
        "print(newdf_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8Qtz742ZVGk"
      },
      "source": [
        "**Split the training set and testing set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "s7gVaZEwEM6v",
        "outputId": "53cf3dcb-54c8-4e44-a5a6-29439abc7499"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ids/.local/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/home/ids/.local/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_S2</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>service_red_i</th>\n",
              "      <th>service_harvest</th>\n",
              "      <th>service_aol</th>\n",
              "      <th>service_http_8001</th>\n",
              "      <th>service_urh_i</th>\n",
              "      <th>service_http_2784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>12983</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22539</th>\n",
              "      <td>0</td>\n",
              "      <td>794</td>\n",
              "      <td>333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22540</th>\n",
              "      <td>0</td>\n",
              "      <td>317</td>\n",
              "      <td>938</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22541</th>\n",
              "      <td>0</td>\n",
              "      <td>54540</td>\n",
              "      <td>8314</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22542</th>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22543</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22544 rows Ã— 123 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
              "0             0          0          0     0               0       0    0   \n",
              "1             0          0          0     0               0       0    0   \n",
              "2             2      12983          0     0               0       0    0   \n",
              "3             0         20          0     0               0       0    0   \n",
              "4             1          0         15     0               0       0    0   \n",
              "...         ...        ...        ...   ...             ...     ...  ...   \n",
              "22539         0        794        333     0               0       0    0   \n",
              "22540         0        317        938     0               0       0    0   \n",
              "22541         0      54540       8314     0               0       0    2   \n",
              "22542         0         42         42     0               0       0    0   \n",
              "22543         0          0          0     0               0       0    0   \n",
              "\n",
              "       num_failed_logins  logged_in  num_compromised  ...  flag_S2  flag_S3  \\\n",
              "0                      0          0                0  ...      0.0      0.0   \n",
              "1                      0          0                0  ...      0.0      0.0   \n",
              "2                      0          0                0  ...      0.0      0.0   \n",
              "3                      0          0                0  ...      0.0      0.0   \n",
              "4                      0          0                0  ...      0.0      0.0   \n",
              "...                  ...        ...              ...  ...      ...      ...   \n",
              "22539                  0          1                0  ...      0.0      0.0   \n",
              "22540                  0          1                0  ...      0.0      0.0   \n",
              "22541                  0          1                1  ...      0.0      0.0   \n",
              "22542                  0          0                0  ...      0.0      0.0   \n",
              "22543                  0          0                0  ...      0.0      0.0   \n",
              "\n",
              "       flag_SF  flag_SH  service_red_i  service_harvest  service_aol  \\\n",
              "0          0.0      0.0              0                0            0   \n",
              "1          0.0      0.0              0                0            0   \n",
              "2          1.0      0.0              0                0            0   \n",
              "3          1.0      0.0              0                0            0   \n",
              "4          0.0      0.0              0                0            0   \n",
              "...        ...      ...            ...              ...          ...   \n",
              "22539      1.0      0.0              0                0            0   \n",
              "22540      1.0      0.0              0                0            0   \n",
              "22541      1.0      0.0              0                0            0   \n",
              "22542      1.0      0.0              0                0            0   \n",
              "22543      0.0      0.0              0                0            0   \n",
              "\n",
              "       service_http_8001  service_urh_i  service_http_2784  \n",
              "0                      0              0                  0  \n",
              "1                      0              0                  0  \n",
              "2                      0              0                  0  \n",
              "3                      0              0                  0  \n",
              "4                      0              0                  0  \n",
              "...                  ...            ...                ...  \n",
              "22539                  0              0                  0  \n",
              "22540                  0              0                  0  \n",
              "22541                  0              0                  0  \n",
              "22542                  0              0                  0  \n",
              "22543                  0              0                  0  \n",
              "\n",
              "[22544 rows x 123 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x=newdf.drop('class',1) #X-train\n",
        "y=newdf[\"class\"] #y-Train\n",
        "xtest=newdf_test.drop(\"class\",1) #X-test\n",
        "ytest=newdf_test['class'] # y-test\n",
        "xtest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wd7HagRwEyzH"
      },
      "outputs": [],
      "source": [
        "# Step 2: the value of every feature is mapped to the [0,1] range linearly\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import preprocessing\n",
        "# Training Set\n",
        "scale = MinMaxScaler()\n",
        "scale= preprocessing.StandardScaler().fit(x)\n",
        "x=scale.transform(x) \n",
        "scaletest= preprocessing.StandardScaler().fit(xtest)\n",
        "xtest=scaletest.transform(xtest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlKG74y2AWXA"
      },
      "source": [
        "# **RNN Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7BNImF3_-4t"
      },
      "source": [
        "**Input layer**\n",
        "\n",
        "LSTM input layer must be 3D\n",
        "the meaning of the 3 input dimensions are: samples, time steps, and features.\n",
        "The number of samples is assumed to be 1 or more.\n",
        "reshape() function takes a tuple as an argument that defines the new shape.\n",
        "number_of_rows_to_process_each_loop, the_time_interval_for_next_move(e.g. per day, per month), column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8w8CdJwK7_H-"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import datetime\n",
        "import time\n",
        "x=pd.DataFrame(x)\n",
        "x = x.values\n",
        "sample = x.shape[0]\n",
        "features = x.shape[1]\n",
        "#Train: convert 2D to 3D for input RNN\n",
        "x_train = np.reshape(x,(sample,features,1)) #shape  = (125973, 18, 1)\n",
        "#Test: convert 2D to 3D for input RNN\n",
        "x_test=pd.DataFrame(xtest)\n",
        "x_test = x_test.values\n",
        "x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybp_hL45CYur"
      },
      "source": [
        "**Following the research paper**\n",
        "\n",
        "Number of neuron in the hidden layer=80\n",
        "\n",
        "The activation function in the hidden layer is sigmoid, in the output layer is softmax function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYs6K7QeB_rh",
        "outputId": "7251d0e3-ffd9-4d37-e55b-bc404a4ec08b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 125973 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-05 10:21:32.862716: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2024-01-05 10:21:32.862757: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2024-01-05 10:21:32.862794: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu22): /proc/driver/nvidia/version does not exist\n",
            "2024-01-05 10:21:32.864358: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2024-01-05 10:21:32.893873: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1997685000 Hz\n",
            "2024-01-05 10:21:32.896169: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xab97760 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2024-01-05 10:21:32.896216: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "125973/125973 [==============================] - 823s 7ms/sample - loss: 0.5346 - acc: 0.4654\n",
            "Epoch 2/10\n",
            "125973/125973 [==============================] - 561s 4ms/sample - loss: 0.5346 - acc: 0.4654\n",
            "Epoch 3/10\n",
            "125973/125973 [==============================] - 547s 4ms/sample - loss: 0.5346 - acc: 0.4654\n",
            "Epoch 4/10\n",
            "125973/125973 [==============================] - 550s 4ms/sample - loss: 0.5346 - acc: 0.4654\n",
            "Epoch 5/10\n",
            "125973/125973 [==============================] - 553s 4ms/sample - loss: 0.5346 - acc: 0.4654\n",
            "Epoch 6/10\n",
            "125973/125973 [==============================] - 554s 4ms/sample - loss: 0.5346 - acc: 0.4654\n",
            "Epoch 7/10\n",
            "125973/125973 [==============================] - 550s 4ms/sample - loss: 0.5346 - acc: 0.4654\n",
            "Epoch 8/10\n",
            "125973/125973 [==============================] - 544s 4ms/sample - loss: 0.5346 - acc: 0.4654\n",
            "Epoch 9/10\n",
            "125973/125973 [==============================] - 547s 4ms/sample - loss: 0.5346 - acc: 0.4654\n",
            "Epoch 10/10\n",
            "125973/125973 [==============================] - 541s 4ms/sample - loss: 0.5346 - acc: 0.4654\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 80)                26240     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 81        \n",
            "=================================================================\n",
            "Total params: 26,321\n",
            "Trainable params: 26,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "/n\n",
            "Accuracy: 56.92%\n"
          ]
        }
      ],
      "source": [
        "Model = keras.Sequential([\n",
        "\n",
        "        keras.layers.LSTM(80,input_shape=(features,x_train.shape[2]),\n",
        "                          activation='sigmoid',recurrent_activation='hard_sigmoid'),\n",
        "        keras.layers.Dense(1,activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "Model.compile(optimizer='rmsprop',loss='mse', metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "\n",
        "Model.fit(x_train, y, epochs=10, batch_size= 32) \n",
        "Model.summary()\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = Model.evaluate(x_test, ytest, verbose=0)\n",
        "print('/n')\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAHsmHTHCi7h"
      },
      "source": [
        "**To modify the results:**\n",
        "\n",
        "number of neurons in the hidden layer is 80 neurons\n",
        "\n",
        "Activation function: I used the hard_sigmoid in the hidden layer\n",
        "and tanh in the output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0W9EW0vcAeC",
        "outputId": "026da343-5bb1-4057-bd98-8bfd3f4b1a4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 125973 samples\n",
            "Epoch 1/10\n",
            "125973/125973 [==============================] - 490s 4ms/sample - loss: 0.0643 - acc: 0.9213\n",
            "Epoch 2/10\n",
            "125973/125973 [==============================] - 495s 4ms/sample - loss: 0.0162 - acc: 0.9814\n",
            "Epoch 3/10\n",
            "125973/125973 [==============================] - 493s 4ms/sample - loss: 0.0056 - acc: 0.9939\n",
            "Epoch 4/10\n",
            "125973/125973 [==============================] - 494s 4ms/sample - loss: 0.0035 - acc: 0.9961\n",
            "Epoch 5/10\n",
            "125973/125973 [==============================] - 494s 4ms/sample - loss: 0.0052 - acc: 0.9943\n",
            "Epoch 6/10\n",
            "125973/125973 [==============================] - 498s 4ms/sample - loss: 0.0025 - acc: 0.9972\n",
            "Epoch 7/10\n",
            "125973/125973 [==============================] - 495s 4ms/sample - loss: 0.0020 - acc: 0.9978\n",
            "Epoch 8/10\n",
            "125973/125973 [==============================] - 497s 4ms/sample - loss: 0.0151 - acc: 0.9814\n",
            "Epoch 9/10\n",
            "125973/125973 [==============================] - 499s 4ms/sample - loss: 0.0030 - acc: 0.9967\n",
            "Epoch 10/10\n",
            "125973/125973 [==============================] - 500s 4ms/sample - loss: 0.0015 - acc: 0.9984\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 80)                26240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 81        \n",
            "=================================================================\n",
            "Total params: 26,321\n",
            "Trainable params: 26,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "/n\n",
            "Accuracy: 85.29%\n"
          ]
        }
      ],
      "source": [
        "# Using tanh and sigmoid as activation functions\n",
        "\n",
        "Model_tanh = keras.Sequential([\n",
        "\n",
        "        keras.layers.LSTM(80,input_shape=(features,x_train.shape[2]),\n",
        "                          activation='tanh',recurrent_activation='hard_sigmoid'),\n",
        "        keras.layers.Dense(1,activation=\"tanh\")\n",
        "    ])\n",
        "\n",
        "Model_tanh.compile(optimizer='rmsprop',loss='mse', metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "Model_tanh.fit(x_train, y, epochs=10, batch_size= 32) \n",
        "Model_tanh.summary()\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = Model_tanh.evaluate(x_test, ytest, verbose=0)\n",
        "print(\"/n\")\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Applying RNN with Meta-learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import learn2learn as l2l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert LSTM RNN model to Pytorch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PyTorchRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size=1):\n",
        "        super(PyTorchRNN, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        output, _ = self.lstm(x)\n",
        "        output = self.tanh(self.fc(output[:, -1, :]))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Converting the Keras model to PyTorch\n",
        "input_shape = x_train.shape[2]\n",
        "hidden_size = 80\n",
        "output_size = 1\n",
        "\n",
        "# # Extract weights from Keras model\n",
        "# weights = [torch.tensor(w) for w in Model.get_weights()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the PyTorch LSTM model\n",
        "pytorch_rnn = PyTorchRNN(input_shape, hidden_size, output_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PyTorchRNN(\n",
              "  (lstm): LSTM(1, 80, batch_first=True)\n",
              "  (fc): Linear(in_features=80, out_features=1, bias=True)\n",
              "  (tanh): Tanh()\n",
              ")"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set PyTorch model to evaluation model\n",
        "pytorch_rnn.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert data to Pytorch tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y, dtype=torch.long)\n",
        "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(ytest, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = TensorDataset(x_test_tensor, y_test_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create MetaDataset for meta-training and meta-testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# meta_train = l2l.data.MetaDataset(train_data)\n",
        "# meta_train_task = l2l.data.TaskDataset(meta_train, \n",
        "#                                        task_transforms=[\n",
        "#                                             l2l.data.transforms.NWays(meta_train, 1),\n",
        "#                                             l2l.data.transforms.KShots(meta_train, 5),\n",
        "#                                             l2l.data.transforms.LoadData(meta_train),\n",
        "#                                             l2l.data.transforms.ConsecutiveLabels(meta_train)\n",
        "#                                             ], num_tasks=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# meta_test = l2l.data.MetaDataset(test_data)\n",
        "# meta_test_task = l2l.data.TaskDataset(meta_test, \n",
        "#                                        task_transforms=[\n",
        "#                                             l2l.data.transforms.NWays(meta_test, 1),\n",
        "#                                             l2l.data.transforms.KShots(meta_test, 5),\n",
        "#                                             l2l.data.transforms.LoadData(meta_test),\n",
        "#                                             l2l.data.transforms.ConsecutiveLabels(meta_test),\n",
        "#                                             ], num_tasks=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "btch_sz = 32\n",
        "train_loader = DataLoader(train_data, batch_size=btch_sz, shuffle=True)\n",
        "test_loader = DataLoader(test_data,batch_size=btch_sz, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MAML-RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "maml_rnn = l2l.algorithms.MAML(pytorch_rnn, lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "meta_optimizer = torch.optim.Adam(maml_rnn.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss = torch.nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_iteration = 1000\n",
        "ways = 5\n",
        "shots = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Meta-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for iteration in range(20000):\n",
        "#     meta_optimizer.zero_grad()\n",
        "#     meta_train_error = 0.0\n",
        "#     meta_train_accuracy = 0.0\n",
        "#     meta_valid_error = 0.0\n",
        "#     meta_valid_accuracy = 0.0\n",
        "#     for task in range(len(meta_train_task)):\n",
        "#         # Compute meta-training loss\n",
        "#         learner = maml_rnn.clone()\n",
        "#         batch = meta_train_task.sample()\n",
        "#         evaluation_error, evaluation_accuracy = fast_adapt(batch, learner, loss, 1, 5, 1)\n",
        "#         evaluation_error.backward()\n",
        "#         meta_train_error += evaluation_error.item()\n",
        "#         meta_train_accuracy += evaluation_accuracy.item()\n",
        "#     # Print some metrics\n",
        "#     print('\\n')\n",
        "#     print('Meta Train Error', meta_train_error / 4)\n",
        "#     print('Meta Train Accuracy', meta_train_accuracy / 4)\n",
        "#     meta_optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Epoch:  1\n",
            "Epoch:  2\n",
            "Epoch:  3\n",
            "Epoch:  4\n",
            "Epoch:  5\n",
            "Epoch:  6\n",
            "Epoch:  7\n",
            "Epoch:  8\n",
            "Epoch:  9\n",
            "Epoch:  10\n",
            "Epoch:  11\n",
            "Epoch:  12\n",
            "Epoch:  13\n",
            "Epoch:  14\n",
            "Epoch:  15\n",
            "Epoch:  16\n",
            "Epoch:  17\n",
            "Epoch:  18\n",
            "Epoch:  19\n",
            "Epoch:  20\n",
            "Epoch:  21\n",
            "Epoch:  22\n",
            "Epoch:  23\n",
            "Epoch:  24\n",
            "Epoch:  25\n",
            "Epoch:  26\n",
            "Epoch:  27\n",
            "Epoch:  28\n",
            "Epoch:  29\n",
            "Epoch:  30\n",
            "Epoch:  31\n",
            "Epoch:  32\n",
            "Epoch:  33\n",
            "Epoch:  34\n",
            "Epoch:  35\n",
            "Epoch:  36\n",
            "Epoch:  37\n",
            "Epoch:  38\n",
            "Epoch:  39\n",
            "Epoch:  40\n",
            "Epoch:  41\n",
            "Epoch:  42\n",
            "Epoch:  43\n",
            "Epoch:  44\n",
            "Epoch:  45\n",
            "Epoch:  46\n",
            "Epoch:  47\n",
            "Epoch:  48\n",
            "Epoch:  49\n",
            "Epoch:  50\n",
            "Epoch:  51\n",
            "Epoch:  52\n",
            "Epoch:  53\n",
            "Epoch:  54\n",
            "Epoch:  55\n",
            "Epoch:  56\n",
            "Epoch:  57\n",
            "Epoch:  58\n",
            "Epoch:  59\n",
            "Epoch:  60\n",
            "Epoch:  61\n",
            "Epoch:  62\n",
            "Epoch:  63\n",
            "Epoch:  64\n",
            "Epoch:  65\n",
            "Epoch:  66\n",
            "Epoch:  67\n",
            "Epoch:  68\n",
            "Epoch:  69\n",
            "Epoch:  70\n",
            "Epoch:  71\n",
            "Epoch:  72\n",
            "Epoch:  73\n",
            "Epoch:  74\n",
            "Epoch:  75\n",
            "Epoch:  76\n",
            "Epoch:  77\n",
            "Epoch:  78\n",
            "Epoch:  79\n",
            "Epoch:  80\n",
            "Epoch:  81\n",
            "Epoch:  82\n",
            "Epoch:  83\n",
            "Epoch:  84\n",
            "Epoch:  85\n",
            "Epoch:  86\n",
            "Epoch:  87\n",
            "Epoch:  88\n",
            "Epoch:  89\n",
            "Epoch:  90\n",
            "Epoch:  91\n",
            "Epoch:  92\n",
            "Epoch:  93\n",
            "Epoch:  94\n",
            "Epoch:  95\n",
            "Epoch:  96\n",
            "Epoch:  97\n",
            "Epoch:  98\n",
            "Epoch:  99\n",
            "Epoch:  100\n",
            "Epoch:  101\n",
            "Epoch:  102\n",
            "Epoch:  103\n",
            "Epoch:  104\n",
            "Epoch:  105\n",
            "Epoch:  106\n",
            "Epoch:  107\n",
            "Epoch:  108\n",
            "Epoch:  109\n",
            "Epoch:  110\n",
            "Epoch:  111\n",
            "Epoch:  112\n",
            "Epoch:  113\n",
            "Epoch:  114\n",
            "Epoch:  115\n",
            "Epoch:  116\n",
            "Epoch:  117\n",
            "Epoch:  118\n",
            "Epoch:  119\n",
            "Epoch:  120\n",
            "Epoch:  121\n",
            "Epoch:  122\n",
            "Epoch:  123\n",
            "Epoch:  124\n",
            "Epoch:  125\n",
            "Epoch:  126\n",
            "Epoch:  127\n",
            "Epoch:  128\n",
            "Epoch:  129\n",
            "Epoch:  130\n",
            "Epoch:  131\n",
            "Epoch:  132\n",
            "Epoch:  133\n",
            "Epoch:  134\n",
            "Epoch:  135\n",
            "Epoch:  136\n",
            "Epoch:  137\n",
            "Epoch:  138\n",
            "Epoch:  139\n",
            "Epoch:  140\n",
            "Epoch:  141\n",
            "Epoch:  142\n",
            "Epoch:  143\n",
            "Epoch:  144\n",
            "Epoch:  145\n",
            "Epoch:  146\n",
            "Epoch:  147\n",
            "Epoch:  148\n",
            "Epoch:  149\n",
            "Epoch:  150\n",
            "Epoch:  151\n",
            "Epoch:  152\n",
            "Epoch:  153\n",
            "Epoch:  154\n",
            "Epoch:  155\n",
            "Epoch:  156\n",
            "Epoch:  157\n",
            "Epoch:  158\n",
            "Epoch:  159\n",
            "Epoch:  160\n",
            "Epoch:  161\n",
            "Epoch:  162\n",
            "Epoch:  163\n",
            "Epoch:  164\n",
            "Epoch:  165\n",
            "Epoch:  166\n",
            "Epoch:  167\n",
            "Epoch:  168\n",
            "Epoch:  169\n",
            "Epoch:  170\n",
            "Epoch:  171\n",
            "Epoch:  172\n",
            "Epoch:  173\n",
            "Epoch:  174\n",
            "Epoch:  175\n",
            "Epoch:  176\n",
            "Epoch:  177\n",
            "Epoch:  178\n",
            "Epoch:  179\n",
            "Epoch:  180\n",
            "Epoch:  181\n",
            "Epoch:  182\n",
            "Epoch:  183\n",
            "Epoch:  184\n",
            "Epoch:  185\n",
            "Epoch:  186\n",
            "Epoch:  187\n",
            "Epoch:  188\n",
            "Epoch:  189\n",
            "Epoch:  190\n",
            "Epoch:  191\n",
            "Epoch:  192\n",
            "Epoch:  193\n",
            "Epoch:  194\n",
            "Epoch:  195\n",
            "Epoch:  196\n",
            "Epoch:  197\n",
            "Epoch:  198\n",
            "Epoch:  199\n",
            "Epoch:  200\n",
            "Epoch:  201\n",
            "Epoch:  202\n",
            "Epoch:  203\n",
            "Epoch:  204\n",
            "Epoch:  205\n",
            "Epoch:  206\n",
            "Epoch:  207\n",
            "Epoch:  208\n",
            "Epoch:  209\n",
            "Epoch:  210\n",
            "Epoch:  211\n",
            "Epoch:  212\n",
            "Epoch:  213\n",
            "Epoch:  214\n",
            "Epoch:  215\n",
            "Epoch:  216\n",
            "Epoch:  217\n",
            "Epoch:  218\n",
            "Epoch:  219\n",
            "Epoch:  220\n",
            "Epoch:  221\n",
            "Epoch:  222\n",
            "Epoch:  223\n",
            "Epoch:  224\n",
            "Epoch:  225\n",
            "Epoch:  226\n",
            "Epoch:  227\n",
            "Epoch:  228\n",
            "Epoch:  229\n",
            "Epoch:  230\n",
            "Epoch:  231\n",
            "Epoch:  232\n",
            "Epoch:  233\n",
            "Epoch:  234\n",
            "Epoch:  235\n",
            "Epoch:  236\n",
            "Epoch:  237\n",
            "Epoch:  238\n",
            "Epoch:  239\n",
            "Epoch:  240\n",
            "Epoch:  241\n",
            "Epoch:  242\n",
            "Epoch:  243\n",
            "Epoch:  244\n",
            "Epoch:  245\n",
            "Epoch:  246\n",
            "Epoch:  247\n",
            "Epoch:  248\n",
            "Epoch:  249\n",
            "Epoch:  250\n",
            "Epoch:  251\n",
            "Epoch:  252\n",
            "Epoch:  253\n",
            "Epoch:  254\n",
            "Epoch:  255\n",
            "Epoch:  256\n",
            "Epoch:  257\n",
            "Epoch:  258\n",
            "Epoch:  259\n",
            "Epoch:  260\n",
            "Epoch:  261\n",
            "Epoch:  262\n",
            "Epoch:  263\n",
            "Epoch:  264\n",
            "Epoch:  265\n",
            "Epoch:  266\n",
            "Epoch:  267\n",
            "Epoch:  268\n",
            "Epoch:  269\n",
            "Epoch:  270\n",
            "Epoch:  271\n",
            "Epoch:  272\n",
            "Epoch:  273\n",
            "Epoch:  274\n",
            "Epoch:  275\n",
            "Epoch:  276\n",
            "Epoch:  277\n",
            "Epoch:  278\n",
            "Epoch:  279\n",
            "Epoch:  280\n",
            "Epoch:  281\n",
            "Epoch:  282\n",
            "Epoch:  283\n",
            "Epoch:  284\n",
            "Epoch:  285\n",
            "Epoch:  286\n",
            "Epoch:  287\n",
            "Epoch:  288\n",
            "Epoch:  289\n",
            "Epoch:  290\n",
            "Epoch:  291\n",
            "Epoch:  292\n",
            "Epoch:  293\n",
            "Epoch:  294\n",
            "Epoch:  295\n",
            "Epoch:  296\n",
            "Epoch:  297\n",
            "Epoch:  298\n",
            "Epoch:  299\n",
            "Epoch:  300\n",
            "Epoch:  301\n",
            "Epoch:  302\n",
            "Epoch:  303\n",
            "Epoch:  304\n",
            "Epoch:  305\n",
            "Epoch:  306\n",
            "Epoch:  307\n",
            "Epoch:  308\n",
            "Epoch:  309\n",
            "Epoch:  310\n",
            "Epoch:  311\n",
            "Epoch:  312\n",
            "Epoch:  313\n",
            "Epoch:  314\n",
            "Epoch:  315\n",
            "Epoch:  316\n",
            "Epoch:  317\n",
            "Epoch:  318\n",
            "Epoch:  319\n",
            "Epoch:  320\n",
            "Epoch:  321\n",
            "Epoch:  322\n",
            "Epoch:  323\n",
            "Epoch:  324\n",
            "Epoch:  325\n",
            "Epoch:  326\n",
            "Epoch:  327\n",
            "Epoch:  328\n",
            "Epoch:  329\n",
            "Epoch:  330\n",
            "Epoch:  331\n",
            "Epoch:  332\n",
            "Epoch:  333\n",
            "Epoch:  334\n",
            "Epoch:  335\n",
            "Epoch:  336\n",
            "Epoch:  337\n",
            "Epoch:  338\n",
            "Epoch:  339\n",
            "Epoch:  340\n",
            "Epoch:  341\n",
            "Epoch:  342\n",
            "Epoch:  343\n",
            "Epoch:  344\n",
            "Epoch:  345\n",
            "Epoch:  346\n",
            "Epoch:  347\n",
            "Epoch:  348\n",
            "Epoch:  349\n",
            "Epoch:  350\n",
            "Epoch:  351\n",
            "Epoch:  352\n",
            "Epoch:  353\n",
            "Epoch:  354\n",
            "Epoch:  355\n",
            "Epoch:  356\n",
            "Epoch:  357\n",
            "Epoch:  358\n",
            "Epoch:  359\n",
            "Epoch:  360\n",
            "Epoch:  361\n",
            "Epoch:  362\n",
            "Epoch:  363\n",
            "Epoch:  364\n",
            "Epoch:  365\n",
            "Epoch:  366\n",
            "Epoch:  367\n",
            "Epoch:  368\n",
            "Epoch:  369\n",
            "Epoch:  370\n",
            "Epoch:  371\n",
            "Epoch:  372\n",
            "Epoch:  373\n",
            "Epoch:  374\n",
            "Epoch:  375\n",
            "Epoch:  376\n",
            "Epoch:  377\n",
            "Epoch:  378\n",
            "Epoch:  379\n",
            "Epoch:  380\n",
            "Epoch:  381\n",
            "Epoch:  382\n",
            "Epoch:  383\n",
            "Epoch:  384\n",
            "Epoch:  385\n",
            "Epoch:  386\n",
            "Epoch:  387\n",
            "Epoch:  388\n",
            "Epoch:  389\n",
            "Epoch:  390\n",
            "Epoch:  391\n",
            "Epoch:  392\n",
            "Epoch:  393\n",
            "Epoch:  394\n",
            "Epoch:  395\n",
            "Epoch:  396\n",
            "Epoch:  397\n",
            "Epoch:  398\n",
            "Epoch:  399\n",
            "Epoch:  400\n",
            "Epoch:  401\n",
            "Epoch:  402\n",
            "Epoch:  403\n",
            "Epoch:  404\n",
            "Epoch:  405\n",
            "Epoch:  406\n",
            "Epoch:  407\n",
            "Epoch:  408\n",
            "Epoch:  409\n",
            "Epoch:  410\n",
            "Epoch:  411\n",
            "Epoch:  412\n",
            "Epoch:  413\n",
            "Epoch:  414\n",
            "Epoch:  415\n",
            "Epoch:  416\n",
            "Epoch:  417\n",
            "Epoch:  418\n",
            "Epoch:  419\n",
            "Epoch:  420\n",
            "Epoch:  421\n",
            "Epoch:  422\n",
            "Epoch:  423\n",
            "Epoch:  424\n",
            "Epoch:  425\n",
            "Epoch:  426\n",
            "Epoch:  427\n",
            "Epoch:  428\n",
            "Epoch:  429\n",
            "Epoch:  430\n",
            "Epoch:  431\n",
            "Epoch:  432\n",
            "Epoch:  433\n",
            "Epoch:  434\n",
            "Epoch:  435\n",
            "Epoch:  436\n",
            "Epoch:  437\n",
            "Epoch:  438\n",
            "Epoch:  439\n",
            "Epoch:  440\n",
            "Epoch:  441\n",
            "Epoch:  442\n",
            "Epoch:  443\n",
            "Epoch:  444\n",
            "Epoch:  445\n",
            "Epoch:  446\n",
            "Epoch:  447\n",
            "Epoch:  448\n",
            "Epoch:  449\n",
            "Epoch:  450\n",
            "Epoch:  451\n",
            "Epoch:  452\n",
            "Epoch:  453\n",
            "Epoch:  454\n",
            "Epoch:  455\n",
            "Epoch:  456\n",
            "Epoch:  457\n",
            "Epoch:  458\n",
            "Epoch:  459\n",
            "Epoch:  460\n",
            "Epoch:  461\n",
            "Epoch:  462\n",
            "Epoch:  463\n",
            "Epoch:  464\n",
            "Epoch:  465\n",
            "Epoch:  466\n",
            "Epoch:  467\n",
            "Epoch:  468\n",
            "Epoch:  469\n",
            "Epoch:  470\n",
            "Epoch:  471\n",
            "Epoch:  472\n",
            "Epoch:  473\n",
            "Epoch:  474\n",
            "Epoch:  475\n",
            "Epoch:  476\n",
            "Epoch:  477\n",
            "Epoch:  478\n",
            "Epoch:  479\n",
            "Epoch:  480\n",
            "Epoch:  481\n",
            "Epoch:  482\n",
            "Epoch:  483\n",
            "Epoch:  484\n",
            "Epoch:  485\n",
            "Epoch:  486\n",
            "Epoch:  487\n",
            "Epoch:  488\n",
            "Epoch:  489\n",
            "Epoch:  490\n",
            "Epoch:  491\n",
            "Epoch:  492\n",
            "Epoch:  493\n",
            "Epoch:  494\n",
            "Epoch:  495\n",
            "Epoch:  496\n",
            "Epoch:  497\n",
            "Epoch:  498\n",
            "Epoch:  499\n",
            "Epoch:  500\n",
            "Epoch:  501\n",
            "Epoch:  502\n",
            "Epoch:  503\n",
            "Epoch:  504\n",
            "Epoch:  505\n",
            "Epoch:  506\n",
            "Epoch:  507\n",
            "Epoch:  508\n",
            "Epoch:  509\n",
            "Epoch:  510\n",
            "Epoch:  511\n",
            "Epoch:  512\n",
            "Epoch:  513\n",
            "Epoch:  514\n",
            "Epoch:  515\n",
            "Epoch:  516\n",
            "Epoch:  517\n",
            "Epoch:  518\n",
            "Epoch:  519\n",
            "Epoch:  520\n",
            "Epoch:  521\n",
            "Epoch:  522\n",
            "Epoch:  523\n",
            "Epoch:  524\n",
            "Epoch:  525\n",
            "Epoch:  526\n",
            "Epoch:  527\n",
            "Epoch:  528\n",
            "Epoch:  529\n",
            "Epoch:  530\n",
            "Epoch:  531\n",
            "Epoch:  532\n",
            "Epoch:  533\n",
            "Epoch:  534\n",
            "Epoch:  535\n",
            "Epoch:  536\n",
            "Epoch:  537\n",
            "Epoch:  538\n",
            "Epoch:  539\n",
            "Epoch:  540\n",
            "Epoch:  541\n",
            "Epoch:  542\n",
            "Epoch:  543\n",
            "Epoch:  544\n",
            "Epoch:  545\n",
            "Epoch:  546\n",
            "Epoch:  547\n",
            "Epoch:  548\n",
            "Epoch:  549\n",
            "Epoch:  550\n",
            "Epoch:  551\n",
            "Epoch:  552\n",
            "Epoch:  553\n",
            "Epoch:  554\n",
            "Epoch:  555\n",
            "Epoch:  556\n",
            "Epoch:  557\n",
            "Epoch:  558\n",
            "Epoch:  559\n",
            "Epoch:  560\n",
            "Epoch:  561\n",
            "Epoch:  562\n",
            "Epoch:  563\n",
            "Epoch:  564\n",
            "Epoch:  565\n",
            "Epoch:  566\n",
            "Epoch:  567\n",
            "Epoch:  568\n",
            "Epoch:  569\n",
            "Epoch:  570\n",
            "Epoch:  571\n",
            "Epoch:  572\n",
            "Epoch:  573\n",
            "Epoch:  574\n",
            "Epoch:  575\n",
            "Epoch:  576\n",
            "Epoch:  577\n",
            "Epoch:  578\n",
            "Epoch:  579\n",
            "Epoch:  580\n",
            "Epoch:  581\n",
            "Epoch:  582\n",
            "Epoch:  583\n",
            "Epoch:  584\n",
            "Epoch:  585\n",
            "Epoch:  586\n",
            "Epoch:  587\n",
            "Epoch:  588\n",
            "Epoch:  589\n",
            "Epoch:  590\n",
            "Epoch:  591\n",
            "Epoch:  592\n",
            "Epoch:  593\n",
            "Epoch:  594\n",
            "Epoch:  595\n",
            "Epoch:  596\n",
            "Epoch:  597\n",
            "Epoch:  598\n",
            "Epoch:  599\n",
            "Epoch:  600\n",
            "Epoch:  601\n",
            "Epoch:  602\n",
            "Epoch:  603\n",
            "Epoch:  604\n",
            "Epoch:  605\n",
            "Epoch:  606\n",
            "Epoch:  607\n",
            "Epoch:  608\n",
            "Epoch:  609\n",
            "Epoch:  610\n",
            "Epoch:  611\n",
            "Epoch:  612\n",
            "Epoch:  613\n",
            "Epoch:  614\n",
            "Epoch:  615\n",
            "Epoch:  616\n",
            "Epoch:  617\n",
            "Epoch:  618\n",
            "Epoch:  619\n",
            "Epoch:  620\n",
            "Epoch:  621\n",
            "Epoch:  622\n",
            "Epoch:  623\n",
            "Epoch:  624\n",
            "Epoch:  625\n",
            "Epoch:  626\n",
            "Epoch:  627\n",
            "Epoch:  628\n",
            "Epoch:  629\n",
            "Epoch:  630\n",
            "Epoch:  631\n",
            "Epoch:  632\n",
            "Epoch:  633\n",
            "Epoch:  634\n",
            "Epoch:  635\n",
            "Epoch:  636\n",
            "Epoch:  637\n",
            "Epoch:  638\n",
            "Epoch:  639\n",
            "Epoch:  640\n",
            "Epoch:  641\n",
            "Epoch:  642\n",
            "Epoch:  643\n",
            "Epoch:  644\n",
            "Epoch:  645\n",
            "Epoch:  646\n",
            "Epoch:  647\n",
            "Epoch:  648\n",
            "Epoch:  649\n",
            "Epoch:  650\n",
            "Epoch:  651\n",
            "Epoch:  652\n",
            "Epoch:  653\n",
            "Epoch:  654\n",
            "Epoch:  655\n",
            "Epoch:  656\n",
            "Epoch:  657\n",
            "Epoch:  658\n",
            "Epoch:  659\n",
            "Epoch:  660\n",
            "Epoch:  661\n",
            "Epoch:  662\n",
            "Epoch:  663\n",
            "Epoch:  664\n",
            "Epoch:  665\n",
            "Epoch:  666\n",
            "Epoch:  667\n",
            "Epoch:  668\n",
            "Epoch:  669\n",
            "Epoch:  670\n",
            "Epoch:  671\n",
            "Epoch:  672\n",
            "Epoch:  673\n",
            "Epoch:  674\n",
            "Epoch:  675\n",
            "Epoch:  676\n",
            "Epoch:  677\n",
            "Epoch:  678\n",
            "Epoch:  679\n",
            "Epoch:  680\n",
            "Epoch:  681\n",
            "Epoch:  682\n",
            "Epoch:  683\n",
            "Epoch:  684\n",
            "Epoch:  685\n",
            "Epoch:  686\n",
            "Epoch:  687\n",
            "Epoch:  688\n",
            "Epoch:  689\n",
            "Epoch:  690\n",
            "Epoch:  691\n",
            "Epoch:  692\n",
            "Epoch:  693\n",
            "Epoch:  694\n",
            "Epoch:  695\n",
            "Epoch:  696\n",
            "Epoch:  697\n",
            "Epoch:  698\n",
            "Epoch:  699\n",
            "Epoch:  700\n",
            "Epoch:  701\n",
            "Epoch:  702\n",
            "Epoch:  703\n",
            "Epoch:  704\n",
            "Epoch:  705\n",
            "Epoch:  706\n",
            "Epoch:  707\n",
            "Epoch:  708\n",
            "Epoch:  709\n",
            "Epoch:  710\n",
            "Epoch:  711\n",
            "Epoch:  712\n",
            "Epoch:  713\n",
            "Epoch:  714\n",
            "Epoch:  715\n",
            "Epoch:  716\n",
            "Epoch:  717\n",
            "Epoch:  718\n",
            "Epoch:  719\n",
            "Epoch:  720\n",
            "Epoch:  721\n",
            "Epoch:  722\n",
            "Epoch:  723\n",
            "Epoch:  724\n",
            "Epoch:  725\n",
            "Epoch:  726\n",
            "Epoch:  727\n",
            "Epoch:  728\n",
            "Epoch:  729\n",
            "Epoch:  730\n",
            "Epoch:  731\n",
            "Epoch:  732\n",
            "Epoch:  733\n",
            "Epoch:  734\n",
            "Epoch:  735\n",
            "Epoch:  736\n",
            "Epoch:  737\n",
            "Epoch:  738\n",
            "Epoch:  739\n",
            "Epoch:  740\n",
            "Epoch:  741\n",
            "Epoch:  742\n",
            "Epoch:  743\n",
            "Epoch:  744\n",
            "Epoch:  745\n",
            "Epoch:  746\n",
            "Epoch:  747\n",
            "Epoch:  748\n",
            "Epoch:  749\n",
            "Epoch:  750\n",
            "Epoch:  751\n",
            "Epoch:  752\n",
            "Epoch:  753\n",
            "Epoch:  754\n",
            "Epoch:  755\n",
            "Epoch:  756\n",
            "Epoch:  757\n",
            "Epoch:  758\n",
            "Epoch:  759\n",
            "Epoch:  760\n",
            "Epoch:  761\n",
            "Epoch:  762\n",
            "Epoch:  763\n",
            "Epoch:  764\n",
            "Epoch:  765\n",
            "Epoch:  766\n",
            "Epoch:  767\n",
            "Epoch:  768\n",
            "Epoch:  769\n",
            "Epoch:  770\n",
            "Epoch:  771\n",
            "Epoch:  772\n",
            "Epoch:  773\n",
            "Epoch:  774\n",
            "Epoch:  775\n",
            "Epoch:  776\n",
            "Epoch:  777\n",
            "Epoch:  778\n",
            "Epoch:  779\n",
            "Epoch:  780\n",
            "Epoch:  781\n",
            "Epoch:  782\n",
            "Epoch:  783\n",
            "Epoch:  784\n",
            "Epoch:  785\n",
            "Epoch:  786\n",
            "Epoch:  787\n",
            "Epoch:  788\n",
            "Epoch:  789\n",
            "Epoch:  790\n",
            "Epoch:  791\n",
            "Epoch:  792\n",
            "Epoch:  793\n",
            "Epoch:  794\n",
            "Epoch:  795\n",
            "Epoch:  796\n",
            "Epoch:  797\n",
            "Epoch:  798\n",
            "Epoch:  799\n",
            "Epoch:  800\n",
            "Epoch:  801\n",
            "Epoch:  802\n",
            "Epoch:  803\n",
            "Epoch:  804\n",
            "Epoch:  805\n",
            "Epoch:  806\n",
            "Epoch:  807\n",
            "Epoch:  808\n",
            "Epoch:  809\n",
            "Epoch:  810\n",
            "Epoch:  811\n",
            "Epoch:  812\n",
            "Epoch:  813\n",
            "Epoch:  814\n",
            "Epoch:  815\n",
            "Epoch:  816\n",
            "Epoch:  817\n",
            "Epoch:  818\n",
            "Epoch:  819\n",
            "Epoch:  820\n",
            "Epoch:  821\n",
            "Epoch:  822\n",
            "Epoch:  823\n",
            "Epoch:  824\n",
            "Epoch:  825\n",
            "Epoch:  826\n",
            "Epoch:  827\n",
            "Epoch:  828\n",
            "Epoch:  829\n",
            "Epoch:  830\n",
            "Epoch:  831\n",
            "Epoch:  832\n",
            "Epoch:  833\n",
            "Epoch:  834\n",
            "Epoch:  835\n",
            "Epoch:  836\n",
            "Epoch:  837\n",
            "Epoch:  838\n",
            "Epoch:  839\n",
            "Epoch:  840\n",
            "Epoch:  841\n",
            "Epoch:  842\n",
            "Epoch:  843\n",
            "Epoch:  844\n",
            "Epoch:  845\n",
            "Epoch:  846\n",
            "Epoch:  847\n",
            "Epoch:  848\n",
            "Epoch:  849\n",
            "Epoch:  850\n",
            "Epoch:  851\n",
            "Epoch:  852\n",
            "Epoch:  853\n",
            "Epoch:  854\n",
            "Epoch:  855\n",
            "Epoch:  856\n",
            "Epoch:  857\n",
            "Epoch:  858\n",
            "Epoch:  859\n",
            "Epoch:  860\n",
            "Epoch:  861\n",
            "Epoch:  862\n",
            "Epoch:  863\n",
            "Epoch:  864\n",
            "Epoch:  865\n",
            "Epoch:  866\n",
            "Epoch:  867\n",
            "Epoch:  868\n",
            "Epoch:  869\n",
            "Epoch:  870\n",
            "Epoch:  871\n",
            "Epoch:  872\n",
            "Epoch:  873\n",
            "Epoch:  874\n",
            "Epoch:  875\n",
            "Epoch:  876\n",
            "Epoch:  877\n",
            "Epoch:  878\n",
            "Epoch:  879\n",
            "Epoch:  880\n",
            "Epoch:  881\n",
            "Epoch:  882\n",
            "Epoch:  883\n",
            "Epoch:  884\n",
            "Epoch:  885\n",
            "Epoch:  886\n",
            "Epoch:  887\n",
            "Epoch:  888\n",
            "Epoch:  889\n",
            "Epoch:  890\n",
            "Epoch:  891\n",
            "Epoch:  892\n",
            "Epoch:  893\n",
            "Epoch:  894\n",
            "Epoch:  895\n",
            "Epoch:  896\n",
            "Epoch:  897\n",
            "Epoch:  898\n",
            "Epoch:  899\n",
            "Epoch:  900\n",
            "Epoch:  901\n",
            "Epoch:  902\n",
            "Epoch:  903\n",
            "Epoch:  904\n",
            "Epoch:  905\n",
            "Epoch:  906\n",
            "Epoch:  907\n",
            "Epoch:  908\n",
            "Epoch:  909\n",
            "Epoch:  910\n",
            "Epoch:  911\n",
            "Epoch:  912\n",
            "Epoch:  913\n",
            "Epoch:  914\n",
            "Epoch:  915\n",
            "Epoch:  916\n",
            "Epoch:  917\n",
            "Epoch:  918\n",
            "Epoch:  919\n",
            "Epoch:  920\n",
            "Epoch:  921\n",
            "Epoch:  922\n",
            "Epoch:  923\n",
            "Epoch:  924\n",
            "Epoch:  925\n",
            "Epoch:  926\n",
            "Epoch:  927\n",
            "Epoch:  928\n",
            "Epoch:  929\n",
            "Epoch:  930\n",
            "Epoch:  931\n",
            "Epoch:  932\n",
            "Epoch:  933\n",
            "Epoch:  934\n",
            "Epoch:  935\n",
            "Epoch:  936\n",
            "Epoch:  937\n",
            "Epoch:  938\n",
            "Epoch:  939\n",
            "Epoch:  940\n",
            "Epoch:  941\n",
            "Epoch:  942\n",
            "Epoch:  943\n",
            "Epoch:  944\n",
            "Epoch:  945\n",
            "Epoch:  946\n",
            "Epoch:  947\n",
            "Epoch:  948\n",
            "Epoch:  949\n",
            "Epoch:  950\n",
            "Epoch:  951\n",
            "Epoch:  952\n",
            "Epoch:  953\n",
            "Epoch:  954\n",
            "Epoch:  955\n",
            "Epoch:  956\n",
            "Epoch:  957\n",
            "Epoch:  958\n",
            "Epoch:  959\n",
            "Epoch:  960\n",
            "Epoch:  961\n",
            "Epoch:  962\n",
            "Epoch:  963\n",
            "Epoch:  964\n",
            "Epoch:  965\n",
            "Epoch:  966\n",
            "Epoch:  967\n",
            "Epoch:  968\n",
            "Epoch:  969\n",
            "Epoch:  970\n",
            "Epoch:  971\n",
            "Epoch:  972\n",
            "Epoch:  973\n",
            "Epoch:  974\n",
            "Epoch:  975\n",
            "Epoch:  976\n",
            "Epoch:  977\n",
            "Epoch:  978\n",
            "Epoch:  979\n",
            "Epoch:  980\n",
            "Epoch:  981\n",
            "Epoch:  982\n",
            "Epoch:  983\n",
            "Epoch:  984\n",
            "Epoch:  985\n",
            "Epoch:  986\n",
            "Epoch:  987\n",
            "Epoch:  988\n",
            "Epoch:  989\n",
            "Epoch:  990\n",
            "Epoch:  991\n",
            "Epoch:  992\n",
            "Epoch:  993\n",
            "Epoch:  994\n",
            "Epoch:  995\n",
            "Epoch:  996\n",
            "Epoch:  997\n",
            "Epoch:  998\n",
            "Epoch:  999\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_iteration):\n",
        "    print(\"Epoch: \", epoch)\n",
        "    for batch in train_loader:\n",
        "        # Split the batch into support and query sets\n",
        "        support = ways * shots\n",
        "        support_dt, query_dt = batch[:support], batch[support:]\n",
        "\n",
        "        # Handle varying dimensions in support data\n",
        "        support_tensors = [item[0] for item in support_dt if item[0].dim() > 0]\n",
        "        if len(support_tensors) == 0:\n",
        "            # Skip if there are no valid errors\n",
        "            continue\n",
        "        support_dt = torch.stack([item.unsqueeze(0) for item in support_tensors], dim=0)\n",
        "\n",
        "        # Handle varying dimensions in support data\n",
        "        query_tensors = [item[0] for item in query_dt if item[0].dim() > 0]\n",
        "        if(len(query_tensors) == 0):\n",
        "            # Skip if there are no valid errors\n",
        "            continue\n",
        "        query_dt = torch.stack([item.unsqueeze(0) for item in query_tensors], dim = 0)\n",
        "\n",
        "        # Meta-training\n",
        "        adapted_model = maml_rnn.clone()\n",
        "        support_loss = adapted_model(support_dt)\n",
        "        adapted_model.adapt(support_loss)\n",
        "        query_loss = adapted_model(query_dt)\n",
        "\n",
        "        meta_optimizer.zero_grad()\n",
        "        query_loss.backward()\n",
        "        meta_optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Meta-testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct: 16\n",
            "Total: 32\n",
            "Correct: 32\n",
            "Total: 64\n",
            "Correct: 49\n",
            "Total: 96\n",
            "Correct: 60\n",
            "Total: 128\n",
            "Correct: 71\n",
            "Total: 160\n",
            "Correct: 81\n",
            "Total: 192\n",
            "Correct: 99\n",
            "Total: 224\n",
            "Correct: 113\n",
            "Total: 256\n",
            "Correct: 124\n",
            "Total: 288\n",
            "Correct: 140\n",
            "Total: 320\n",
            "Correct: 152\n",
            "Total: 352\n",
            "Correct: 169\n",
            "Total: 384\n",
            "Correct: 187\n",
            "Total: 416\n",
            "Correct: 205\n",
            "Total: 448\n",
            "Correct: 220\n",
            "Total: 480\n",
            "Correct: 233\n",
            "Total: 512\n",
            "Correct: 247\n",
            "Total: 544\n",
            "Correct: 267\n",
            "Total: 576\n",
            "Correct: 280\n",
            "Total: 608\n",
            "Correct: 288\n",
            "Total: 640\n",
            "Correct: 304\n",
            "Total: 672\n",
            "Correct: 320\n",
            "Total: 704\n",
            "Correct: 336\n",
            "Total: 736\n",
            "Correct: 353\n",
            "Total: 768\n",
            "Correct: 370\n",
            "Total: 800\n",
            "Correct: 388\n",
            "Total: 832\n",
            "Correct: 399\n",
            "Total: 864\n",
            "Correct: 412\n",
            "Total: 896\n",
            "Correct: 424\n",
            "Total: 928\n",
            "Correct: 439\n",
            "Total: 960\n",
            "Correct: 451\n",
            "Total: 992\n",
            "Correct: 461\n",
            "Total: 1024\n",
            "Correct: 478\n",
            "Total: 1056\n",
            "Correct: 491\n",
            "Total: 1088\n",
            "Correct: 507\n",
            "Total: 1120\n",
            "Correct: 517\n",
            "Total: 1152\n",
            "Correct: 531\n",
            "Total: 1184\n",
            "Correct: 543\n",
            "Total: 1216\n",
            "Correct: 556\n",
            "Total: 1248\n",
            "Correct: 571\n",
            "Total: 1280\n",
            "Correct: 581\n",
            "Total: 1312\n",
            "Correct: 594\n",
            "Total: 1344\n",
            "Correct: 606\n",
            "Total: 1376\n",
            "Correct: 620\n",
            "Total: 1408\n",
            "Correct: 633\n",
            "Total: 1440\n",
            "Correct: 648\n",
            "Total: 1472\n",
            "Correct: 667\n",
            "Total: 1504\n",
            "Correct: 685\n",
            "Total: 1536\n",
            "Correct: 700\n",
            "Total: 1568\n",
            "Correct: 713\n",
            "Total: 1600\n",
            "Correct: 727\n",
            "Total: 1632\n",
            "Correct: 743\n",
            "Total: 1664\n",
            "Correct: 763\n",
            "Total: 1696\n",
            "Correct: 778\n",
            "Total: 1728\n",
            "Correct: 791\n",
            "Total: 1760\n",
            "Correct: 806\n",
            "Total: 1792\n",
            "Correct: 822\n",
            "Total: 1824\n",
            "Correct: 832\n",
            "Total: 1856\n",
            "Correct: 843\n",
            "Total: 1888\n",
            "Correct: 855\n",
            "Total: 1920\n",
            "Correct: 867\n",
            "Total: 1952\n",
            "Correct: 880\n",
            "Total: 1984\n",
            "Correct: 892\n",
            "Total: 2016\n",
            "Correct: 901\n",
            "Total: 2048\n",
            "Correct: 922\n",
            "Total: 2080\n",
            "Correct: 936\n",
            "Total: 2112\n",
            "Correct: 949\n",
            "Total: 2144\n",
            "Correct: 960\n",
            "Total: 2176\n",
            "Correct: 976\n",
            "Total: 2208\n",
            "Correct: 984\n",
            "Total: 2240\n",
            "Correct: 995\n",
            "Total: 2272\n",
            "Correct: 1011\n",
            "Total: 2304\n",
            "Correct: 1027\n",
            "Total: 2336\n",
            "Correct: 1037\n",
            "Total: 2368\n",
            "Correct: 1051\n",
            "Total: 2400\n",
            "Correct: 1065\n",
            "Total: 2432\n",
            "Correct: 1077\n",
            "Total: 2464\n",
            "Correct: 1094\n",
            "Total: 2496\n",
            "Correct: 1107\n",
            "Total: 2528\n",
            "Correct: 1121\n",
            "Total: 2560\n",
            "Correct: 1140\n",
            "Total: 2592\n",
            "Correct: 1153\n",
            "Total: 2624\n",
            "Correct: 1172\n",
            "Total: 2656\n",
            "Correct: 1186\n",
            "Total: 2688\n",
            "Correct: 1204\n",
            "Total: 2720\n",
            "Correct: 1209\n",
            "Total: 2752\n",
            "Correct: 1226\n",
            "Total: 2784\n",
            "Correct: 1239\n",
            "Total: 2816\n",
            "Correct: 1247\n",
            "Total: 2848\n",
            "Correct: 1266\n",
            "Total: 2880\n",
            "Correct: 1280\n",
            "Total: 2912\n",
            "Correct: 1296\n",
            "Total: 2944\n",
            "Correct: 1310\n",
            "Total: 2976\n",
            "Correct: 1327\n",
            "Total: 3008\n",
            "Correct: 1338\n",
            "Total: 3040\n",
            "Correct: 1352\n",
            "Total: 3072\n",
            "Correct: 1364\n",
            "Total: 3104\n",
            "Correct: 1379\n",
            "Total: 3136\n",
            "Correct: 1389\n",
            "Total: 3168\n",
            "Correct: 1405\n",
            "Total: 3200\n",
            "Correct: 1416\n",
            "Total: 3232\n",
            "Correct: 1434\n",
            "Total: 3264\n",
            "Correct: 1443\n",
            "Total: 3296\n",
            "Correct: 1457\n",
            "Total: 3328\n",
            "Correct: 1470\n",
            "Total: 3360\n",
            "Correct: 1483\n",
            "Total: 3392\n",
            "Correct: 1492\n",
            "Total: 3424\n",
            "Correct: 1504\n",
            "Total: 3456\n",
            "Correct: 1517\n",
            "Total: 3488\n",
            "Correct: 1529\n",
            "Total: 3520\n",
            "Correct: 1544\n",
            "Total: 3552\n",
            "Correct: 1556\n",
            "Total: 3584\n",
            "Correct: 1569\n",
            "Total: 3616\n",
            "Correct: 1579\n",
            "Total: 3648\n",
            "Correct: 1587\n",
            "Total: 3680\n",
            "Correct: 1599\n",
            "Total: 3712\n",
            "Correct: 1612\n",
            "Total: 3744\n",
            "Correct: 1627\n",
            "Total: 3776\n",
            "Correct: 1641\n",
            "Total: 3808\n",
            "Correct: 1650\n",
            "Total: 3840\n",
            "Correct: 1661\n",
            "Total: 3872\n",
            "Correct: 1673\n",
            "Total: 3904\n",
            "Correct: 1690\n",
            "Total: 3936\n",
            "Correct: 1700\n",
            "Total: 3968\n",
            "Correct: 1716\n",
            "Total: 4000\n",
            "Correct: 1726\n",
            "Total: 4032\n",
            "Correct: 1739\n",
            "Total: 4064\n",
            "Correct: 1754\n",
            "Total: 4096\n",
            "Correct: 1765\n",
            "Total: 4128\n",
            "Correct: 1781\n",
            "Total: 4160\n",
            "Correct: 1796\n",
            "Total: 4192\n",
            "Correct: 1809\n",
            "Total: 4224\n",
            "Correct: 1819\n",
            "Total: 4256\n",
            "Correct: 1831\n",
            "Total: 4288\n",
            "Correct: 1844\n",
            "Total: 4320\n",
            "Correct: 1858\n",
            "Total: 4352\n",
            "Correct: 1872\n",
            "Total: 4384\n",
            "Correct: 1889\n",
            "Total: 4416\n",
            "Correct: 1902\n",
            "Total: 4448\n",
            "Correct: 1921\n",
            "Total: 4480\n",
            "Correct: 1937\n",
            "Total: 4512\n",
            "Correct: 1950\n",
            "Total: 4544\n",
            "Correct: 1964\n",
            "Total: 4576\n",
            "Correct: 1978\n",
            "Total: 4608\n",
            "Correct: 1994\n",
            "Total: 4640\n",
            "Correct: 2005\n",
            "Total: 4672\n",
            "Correct: 2018\n",
            "Total: 4704\n",
            "Correct: 2036\n",
            "Total: 4736\n",
            "Correct: 2049\n",
            "Total: 4768\n",
            "Correct: 2061\n",
            "Total: 4800\n",
            "Correct: 2077\n",
            "Total: 4832\n",
            "Correct: 2089\n",
            "Total: 4864\n",
            "Correct: 2104\n",
            "Total: 4896\n",
            "Correct: 2116\n",
            "Total: 4928\n",
            "Correct: 2129\n",
            "Total: 4960\n",
            "Correct: 2143\n",
            "Total: 4992\n",
            "Correct: 2160\n",
            "Total: 5024\n",
            "Correct: 2171\n",
            "Total: 5056\n",
            "Correct: 2183\n",
            "Total: 5088\n",
            "Correct: 2195\n",
            "Total: 5120\n",
            "Correct: 2205\n",
            "Total: 5152\n",
            "Correct: 2220\n",
            "Total: 5184\n",
            "Correct: 2232\n",
            "Total: 5216\n",
            "Correct: 2245\n",
            "Total: 5248\n",
            "Correct: 2259\n",
            "Total: 5280\n",
            "Correct: 2274\n",
            "Total: 5312\n",
            "Correct: 2286\n",
            "Total: 5344\n",
            "Correct: 2300\n",
            "Total: 5376\n",
            "Correct: 2310\n",
            "Total: 5408\n",
            "Correct: 2319\n",
            "Total: 5440\n",
            "Correct: 2326\n",
            "Total: 5472\n",
            "Correct: 2339\n",
            "Total: 5504\n",
            "Correct: 2356\n",
            "Total: 5536\n",
            "Correct: 2371\n",
            "Total: 5568\n",
            "Correct: 2382\n",
            "Total: 5600\n",
            "Correct: 2398\n",
            "Total: 5632\n",
            "Correct: 2413\n",
            "Total: 5664\n",
            "Correct: 2431\n",
            "Total: 5696\n",
            "Correct: 2441\n",
            "Total: 5728\n",
            "Correct: 2450\n",
            "Total: 5760\n",
            "Correct: 2462\n",
            "Total: 5792\n",
            "Correct: 2475\n",
            "Total: 5824\n",
            "Correct: 2487\n",
            "Total: 5856\n",
            "Correct: 2499\n",
            "Total: 5888\n",
            "Correct: 2511\n",
            "Total: 5920\n",
            "Correct: 2526\n",
            "Total: 5952\n",
            "Correct: 2541\n",
            "Total: 5984\n",
            "Correct: 2552\n",
            "Total: 6016\n",
            "Correct: 2564\n",
            "Total: 6048\n",
            "Correct: 2578\n",
            "Total: 6080\n",
            "Correct: 2584\n",
            "Total: 6112\n",
            "Correct: 2595\n",
            "Total: 6144\n",
            "Correct: 2602\n",
            "Total: 6176\n",
            "Correct: 2614\n",
            "Total: 6208\n",
            "Correct: 2630\n",
            "Total: 6240\n",
            "Correct: 2647\n",
            "Total: 6272\n",
            "Correct: 2655\n",
            "Total: 6304\n",
            "Correct: 2665\n",
            "Total: 6336\n",
            "Correct: 2677\n",
            "Total: 6368\n",
            "Correct: 2694\n",
            "Total: 6400\n",
            "Correct: 2706\n",
            "Total: 6432\n",
            "Correct: 2723\n",
            "Total: 6464\n",
            "Correct: 2732\n",
            "Total: 6496\n",
            "Correct: 2750\n",
            "Total: 6528\n",
            "Correct: 2761\n",
            "Total: 6560\n",
            "Correct: 2771\n",
            "Total: 6592\n",
            "Correct: 2785\n",
            "Total: 6624\n",
            "Correct: 2800\n",
            "Total: 6656\n",
            "Correct: 2816\n",
            "Total: 6688\n",
            "Correct: 2832\n",
            "Total: 6720\n",
            "Correct: 2846\n",
            "Total: 6752\n",
            "Correct: 2861\n",
            "Total: 6784\n",
            "Correct: 2875\n",
            "Total: 6816\n",
            "Correct: 2884\n",
            "Total: 6848\n",
            "Correct: 2901\n",
            "Total: 6880\n",
            "Correct: 2914\n",
            "Total: 6912\n",
            "Correct: 2923\n",
            "Total: 6944\n",
            "Correct: 2939\n",
            "Total: 6976\n",
            "Correct: 2956\n",
            "Total: 7008\n",
            "Correct: 2969\n",
            "Total: 7040\n",
            "Correct: 2981\n",
            "Total: 7072\n",
            "Correct: 2989\n",
            "Total: 7104\n",
            "Correct: 3005\n",
            "Total: 7136\n",
            "Correct: 3023\n",
            "Total: 7168\n",
            "Correct: 3034\n",
            "Total: 7200\n",
            "Correct: 3047\n",
            "Total: 7232\n",
            "Correct: 3061\n",
            "Total: 7264\n",
            "Correct: 3072\n",
            "Total: 7296\n",
            "Correct: 3084\n",
            "Total: 7328\n",
            "Correct: 3097\n",
            "Total: 7360\n",
            "Correct: 3113\n",
            "Total: 7392\n",
            "Correct: 3130\n",
            "Total: 7424\n",
            "Correct: 3143\n",
            "Total: 7456\n",
            "Correct: 3156\n",
            "Total: 7488\n",
            "Correct: 3171\n",
            "Total: 7520\n",
            "Correct: 3182\n",
            "Total: 7552\n",
            "Correct: 3195\n",
            "Total: 7584\n",
            "Correct: 3215\n",
            "Total: 7616\n",
            "Correct: 3227\n",
            "Total: 7648\n",
            "Correct: 3240\n",
            "Total: 7680\n",
            "Correct: 3256\n",
            "Total: 7712\n",
            "Correct: 3274\n",
            "Total: 7744\n",
            "Correct: 3289\n",
            "Total: 7776\n",
            "Correct: 3306\n",
            "Total: 7808\n",
            "Correct: 3319\n",
            "Total: 7840\n",
            "Correct: 3335\n",
            "Total: 7872\n",
            "Correct: 3351\n",
            "Total: 7904\n",
            "Correct: 3365\n",
            "Total: 7936\n",
            "Correct: 3379\n",
            "Total: 7968\n",
            "Correct: 3392\n",
            "Total: 8000\n",
            "Correct: 3404\n",
            "Total: 8032\n",
            "Correct: 3413\n",
            "Total: 8064\n",
            "Correct: 3427\n",
            "Total: 8096\n",
            "Correct: 3440\n",
            "Total: 8128\n",
            "Correct: 3452\n",
            "Total: 8160\n",
            "Correct: 3470\n",
            "Total: 8192\n",
            "Correct: 3488\n",
            "Total: 8224\n",
            "Correct: 3500\n",
            "Total: 8256\n",
            "Correct: 3516\n",
            "Total: 8288\n",
            "Correct: 3533\n",
            "Total: 8320\n",
            "Correct: 3542\n",
            "Total: 8352\n",
            "Correct: 3558\n",
            "Total: 8384\n",
            "Correct: 3569\n",
            "Total: 8416\n",
            "Correct: 3581\n",
            "Total: 8448\n",
            "Correct: 3590\n",
            "Total: 8480\n",
            "Correct: 3601\n",
            "Total: 8512\n",
            "Correct: 3615\n",
            "Total: 8544\n",
            "Correct: 3627\n",
            "Total: 8576\n",
            "Correct: 3640\n",
            "Total: 8608\n",
            "Correct: 3656\n",
            "Total: 8640\n",
            "Correct: 3672\n",
            "Total: 8672\n",
            "Correct: 3686\n",
            "Total: 8704\n",
            "Correct: 3700\n",
            "Total: 8736\n",
            "Correct: 3715\n",
            "Total: 8768\n",
            "Correct: 3733\n",
            "Total: 8800\n",
            "Correct: 3744\n",
            "Total: 8832\n",
            "Correct: 3755\n",
            "Total: 8864\n",
            "Correct: 3764\n",
            "Total: 8896\n",
            "Correct: 3781\n",
            "Total: 8928\n",
            "Correct: 3796\n",
            "Total: 8960\n",
            "Correct: 3807\n",
            "Total: 8992\n",
            "Correct: 3820\n",
            "Total: 9024\n",
            "Correct: 3835\n",
            "Total: 9056\n",
            "Correct: 3843\n",
            "Total: 9088\n",
            "Correct: 3860\n",
            "Total: 9120\n",
            "Correct: 3875\n",
            "Total: 9152\n",
            "Correct: 3887\n",
            "Total: 9184\n",
            "Correct: 3898\n",
            "Total: 9216\n",
            "Correct: 3909\n",
            "Total: 9248\n",
            "Correct: 3925\n",
            "Total: 9280\n",
            "Correct: 3937\n",
            "Total: 9312\n",
            "Correct: 3950\n",
            "Total: 9344\n",
            "Correct: 3969\n",
            "Total: 9376\n",
            "Correct: 3984\n",
            "Total: 9408\n",
            "Correct: 3999\n",
            "Total: 9440\n",
            "Correct: 4010\n",
            "Total: 9472\n",
            "Correct: 4028\n",
            "Total: 9504\n",
            "Correct: 4046\n",
            "Total: 9536\n",
            "Correct: 4058\n",
            "Total: 9568\n",
            "Correct: 4078\n",
            "Total: 9600\n",
            "Correct: 4091\n",
            "Total: 9632\n",
            "Correct: 4109\n",
            "Total: 9664\n",
            "Correct: 4127\n",
            "Total: 9696\n",
            "Correct: 4139\n",
            "Total: 9728\n",
            "Correct: 4148\n",
            "Total: 9760\n",
            "Correct: 4159\n",
            "Total: 9792\n",
            "Correct: 4173\n",
            "Total: 9824\n",
            "Correct: 4190\n",
            "Total: 9856\n",
            "Correct: 4207\n",
            "Total: 9888\n",
            "Correct: 4222\n",
            "Total: 9920\n",
            "Correct: 4235\n",
            "Total: 9952\n",
            "Correct: 4253\n",
            "Total: 9984\n",
            "Correct: 4263\n",
            "Total: 10016\n",
            "Correct: 4277\n",
            "Total: 10048\n",
            "Correct: 4295\n",
            "Total: 10080\n",
            "Correct: 4310\n",
            "Total: 10112\n",
            "Correct: 4323\n",
            "Total: 10144\n",
            "Correct: 4340\n",
            "Total: 10176\n",
            "Correct: 4351\n",
            "Total: 10208\n",
            "Correct: 4366\n",
            "Total: 10240\n",
            "Correct: 4382\n",
            "Total: 10272\n",
            "Correct: 4394\n",
            "Total: 10304\n",
            "Correct: 4412\n",
            "Total: 10336\n",
            "Correct: 4429\n",
            "Total: 10368\n",
            "Correct: 4444\n",
            "Total: 10400\n",
            "Correct: 4464\n",
            "Total: 10432\n",
            "Correct: 4486\n",
            "Total: 10464\n",
            "Correct: 4498\n",
            "Total: 10496\n",
            "Correct: 4513\n",
            "Total: 10528\n",
            "Correct: 4531\n",
            "Total: 10560\n",
            "Correct: 4545\n",
            "Total: 10592\n",
            "Correct: 4558\n",
            "Total: 10624\n",
            "Correct: 4571\n",
            "Total: 10656\n",
            "Correct: 4587\n",
            "Total: 10688\n",
            "Correct: 4602\n",
            "Total: 10720\n",
            "Correct: 4618\n",
            "Total: 10752\n",
            "Correct: 4635\n",
            "Total: 10784\n",
            "Correct: 4648\n",
            "Total: 10816\n",
            "Correct: 4660\n",
            "Total: 10848\n",
            "Correct: 4680\n",
            "Total: 10880\n",
            "Correct: 4692\n",
            "Total: 10912\n",
            "Correct: 4709\n",
            "Total: 10944\n",
            "Correct: 4722\n",
            "Total: 10976\n",
            "Correct: 4734\n",
            "Total: 11008\n",
            "Correct: 4750\n",
            "Total: 11040\n",
            "Correct: 4760\n",
            "Total: 11072\n",
            "Correct: 4774\n",
            "Total: 11104\n",
            "Correct: 4788\n",
            "Total: 11136\n",
            "Correct: 4800\n",
            "Total: 11168\n",
            "Correct: 4814\n",
            "Total: 11200\n",
            "Correct: 4826\n",
            "Total: 11232\n",
            "Correct: 4839\n",
            "Total: 11264\n",
            "Correct: 4851\n",
            "Total: 11296\n",
            "Correct: 4863\n",
            "Total: 11328\n",
            "Correct: 4878\n",
            "Total: 11360\n",
            "Correct: 4892\n",
            "Total: 11392\n",
            "Correct: 4912\n",
            "Total: 11424\n",
            "Correct: 4926\n",
            "Total: 11456\n",
            "Correct: 4942\n",
            "Total: 11488\n",
            "Correct: 4955\n",
            "Total: 11520\n",
            "Correct: 4970\n",
            "Total: 11552\n",
            "Correct: 4984\n",
            "Total: 11584\n",
            "Correct: 4999\n",
            "Total: 11616\n",
            "Correct: 5015\n",
            "Total: 11648\n",
            "Correct: 5027\n",
            "Total: 11680\n",
            "Correct: 5042\n",
            "Total: 11712\n",
            "Correct: 5058\n",
            "Total: 11744\n",
            "Correct: 5075\n",
            "Total: 11776\n",
            "Correct: 5087\n",
            "Total: 11808\n",
            "Correct: 5107\n",
            "Total: 11840\n",
            "Correct: 5121\n",
            "Total: 11872\n",
            "Correct: 5134\n",
            "Total: 11904\n",
            "Correct: 5150\n",
            "Total: 11936\n",
            "Correct: 5166\n",
            "Total: 11968\n",
            "Correct: 5182\n",
            "Total: 12000\n",
            "Correct: 5192\n",
            "Total: 12032\n",
            "Correct: 5209\n",
            "Total: 12064\n",
            "Correct: 5222\n",
            "Total: 12096\n",
            "Correct: 5236\n",
            "Total: 12128\n",
            "Correct: 5254\n",
            "Total: 12160\n",
            "Correct: 5267\n",
            "Total: 12192\n",
            "Correct: 5281\n",
            "Total: 12224\n",
            "Correct: 5295\n",
            "Total: 12256\n",
            "Correct: 5303\n",
            "Total: 12288\n",
            "Correct: 5314\n",
            "Total: 12320\n",
            "Correct: 5325\n",
            "Total: 12352\n",
            "Correct: 5336\n",
            "Total: 12384\n",
            "Correct: 5347\n",
            "Total: 12416\n",
            "Correct: 5364\n",
            "Total: 12448\n",
            "Correct: 5378\n",
            "Total: 12480\n",
            "Correct: 5391\n",
            "Total: 12512\n",
            "Correct: 5406\n",
            "Total: 12544\n",
            "Correct: 5418\n",
            "Total: 12576\n",
            "Correct: 5430\n",
            "Total: 12608\n",
            "Correct: 5447\n",
            "Total: 12640\n",
            "Correct: 5461\n",
            "Total: 12672\n",
            "Correct: 5477\n",
            "Total: 12704\n",
            "Correct: 5490\n",
            "Total: 12736\n",
            "Correct: 5499\n",
            "Total: 12768\n",
            "Correct: 5514\n",
            "Total: 12800\n",
            "Correct: 5526\n",
            "Total: 12832\n",
            "Correct: 5533\n",
            "Total: 12864\n",
            "Correct: 5545\n",
            "Total: 12896\n",
            "Correct: 5562\n",
            "Total: 12928\n",
            "Correct: 5574\n",
            "Total: 12960\n",
            "Correct: 5586\n",
            "Total: 12992\n",
            "Correct: 5596\n",
            "Total: 13024\n",
            "Correct: 5607\n",
            "Total: 13056\n",
            "Correct: 5621\n",
            "Total: 13088\n",
            "Correct: 5632\n",
            "Total: 13120\n",
            "Correct: 5643\n",
            "Total: 13152\n",
            "Correct: 5660\n",
            "Total: 13184\n",
            "Correct: 5676\n",
            "Total: 13216\n",
            "Correct: 5692\n",
            "Total: 13248\n",
            "Correct: 5708\n",
            "Total: 13280\n",
            "Correct: 5721\n",
            "Total: 13312\n",
            "Correct: 5732\n",
            "Total: 13344\n",
            "Correct: 5749\n",
            "Total: 13376\n",
            "Correct: 5761\n",
            "Total: 13408\n",
            "Correct: 5777\n",
            "Total: 13440\n",
            "Correct: 5792\n",
            "Total: 13472\n",
            "Correct: 5805\n",
            "Total: 13504\n",
            "Correct: 5819\n",
            "Total: 13536\n",
            "Correct: 5831\n",
            "Total: 13568\n",
            "Correct: 5849\n",
            "Total: 13600\n",
            "Correct: 5859\n",
            "Total: 13632\n",
            "Correct: 5874\n",
            "Total: 13664\n",
            "Correct: 5890\n",
            "Total: 13696\n",
            "Correct: 5905\n",
            "Total: 13728\n",
            "Correct: 5916\n",
            "Total: 13760\n",
            "Correct: 5924\n",
            "Total: 13792\n",
            "Correct: 5934\n",
            "Total: 13824\n",
            "Correct: 5947\n",
            "Total: 13856\n",
            "Correct: 5958\n",
            "Total: 13888\n",
            "Correct: 5973\n",
            "Total: 13920\n",
            "Correct: 5988\n",
            "Total: 13952\n",
            "Correct: 6006\n",
            "Total: 13984\n",
            "Correct: 6017\n",
            "Total: 14016\n",
            "Correct: 6028\n",
            "Total: 14048\n",
            "Correct: 6044\n",
            "Total: 14080\n",
            "Correct: 6056\n",
            "Total: 14112\n",
            "Correct: 6066\n",
            "Total: 14144\n",
            "Correct: 6080\n",
            "Total: 14176\n",
            "Correct: 6093\n",
            "Total: 14208\n",
            "Correct: 6102\n",
            "Total: 14240\n",
            "Correct: 6117\n",
            "Total: 14272\n",
            "Correct: 6130\n",
            "Total: 14304\n",
            "Correct: 6148\n",
            "Total: 14336\n",
            "Correct: 6160\n",
            "Total: 14368\n",
            "Correct: 6174\n",
            "Total: 14400\n",
            "Correct: 6194\n",
            "Total: 14432\n",
            "Correct: 6212\n",
            "Total: 14464\n",
            "Correct: 6225\n",
            "Total: 14496\n",
            "Correct: 6239\n",
            "Total: 14528\n",
            "Correct: 6252\n",
            "Total: 14560\n",
            "Correct: 6267\n",
            "Total: 14592\n",
            "Correct: 6280\n",
            "Total: 14624\n",
            "Correct: 6294\n",
            "Total: 14656\n",
            "Correct: 6310\n",
            "Total: 14688\n",
            "Correct: 6327\n",
            "Total: 14720\n",
            "Correct: 6336\n",
            "Total: 14752\n",
            "Correct: 6349\n",
            "Total: 14784\n",
            "Correct: 6364\n",
            "Total: 14816\n",
            "Correct: 6376\n",
            "Total: 14848\n",
            "Correct: 6388\n",
            "Total: 14880\n",
            "Correct: 6404\n",
            "Total: 14912\n",
            "Correct: 6417\n",
            "Total: 14944\n",
            "Correct: 6431\n",
            "Total: 14976\n",
            "Correct: 6447\n",
            "Total: 15008\n",
            "Correct: 6466\n",
            "Total: 15040\n",
            "Correct: 6479\n",
            "Total: 15072\n",
            "Correct: 6490\n",
            "Total: 15104\n",
            "Correct: 6503\n",
            "Total: 15136\n",
            "Correct: 6513\n",
            "Total: 15168\n",
            "Correct: 6536\n",
            "Total: 15200\n",
            "Correct: 6547\n",
            "Total: 15232\n",
            "Correct: 6562\n",
            "Total: 15264\n",
            "Correct: 6579\n",
            "Total: 15296\n",
            "Correct: 6588\n",
            "Total: 15328\n",
            "Correct: 6603\n",
            "Total: 15360\n",
            "Correct: 6619\n",
            "Total: 15392\n",
            "Correct: 6632\n",
            "Total: 15424\n",
            "Correct: 6649\n",
            "Total: 15456\n",
            "Correct: 6659\n",
            "Total: 15488\n",
            "Correct: 6673\n",
            "Total: 15520\n",
            "Correct: 6688\n",
            "Total: 15552\n",
            "Correct: 6701\n",
            "Total: 15584\n",
            "Correct: 6717\n",
            "Total: 15616\n",
            "Correct: 6731\n",
            "Total: 15648\n",
            "Correct: 6741\n",
            "Total: 15680\n",
            "Correct: 6762\n",
            "Total: 15712\n",
            "Correct: 6775\n",
            "Total: 15744\n",
            "Correct: 6784\n",
            "Total: 15776\n",
            "Correct: 6793\n",
            "Total: 15808\n",
            "Correct: 6807\n",
            "Total: 15840\n",
            "Correct: 6824\n",
            "Total: 15872\n",
            "Correct: 6839\n",
            "Total: 15904\n",
            "Correct: 6851\n",
            "Total: 15936\n",
            "Correct: 6866\n",
            "Total: 15968\n",
            "Correct: 6878\n",
            "Total: 16000\n",
            "Correct: 6888\n",
            "Total: 16032\n",
            "Correct: 6902\n",
            "Total: 16064\n",
            "Correct: 6918\n",
            "Total: 16096\n",
            "Correct: 6927\n",
            "Total: 16128\n",
            "Correct: 6948\n",
            "Total: 16160\n",
            "Correct: 6961\n",
            "Total: 16192\n",
            "Correct: 6974\n",
            "Total: 16224\n",
            "Correct: 6986\n",
            "Total: 16256\n",
            "Correct: 6998\n",
            "Total: 16288\n",
            "Correct: 7011\n",
            "Total: 16320\n",
            "Correct: 7019\n",
            "Total: 16352\n",
            "Correct: 7035\n",
            "Total: 16384\n",
            "Correct: 7047\n",
            "Total: 16416\n",
            "Correct: 7061\n",
            "Total: 16448\n",
            "Correct: 7072\n",
            "Total: 16480\n",
            "Correct: 7083\n",
            "Total: 16512\n",
            "Correct: 7095\n",
            "Total: 16544\n",
            "Correct: 7109\n",
            "Total: 16576\n",
            "Correct: 7124\n",
            "Total: 16608\n",
            "Correct: 7140\n",
            "Total: 16640\n",
            "Correct: 7153\n",
            "Total: 16672\n",
            "Correct: 7165\n",
            "Total: 16704\n",
            "Correct: 7178\n",
            "Total: 16736\n",
            "Correct: 7197\n",
            "Total: 16768\n",
            "Correct: 7213\n",
            "Total: 16800\n",
            "Correct: 7226\n",
            "Total: 16832\n",
            "Correct: 7242\n",
            "Total: 16864\n",
            "Correct: 7255\n",
            "Total: 16896\n",
            "Correct: 7268\n",
            "Total: 16928\n",
            "Correct: 7279\n",
            "Total: 16960\n",
            "Correct: 7297\n",
            "Total: 16992\n",
            "Correct: 7314\n",
            "Total: 17024\n",
            "Correct: 7325\n",
            "Total: 17056\n",
            "Correct: 7340\n",
            "Total: 17088\n",
            "Correct: 7352\n",
            "Total: 17120\n",
            "Correct: 7369\n",
            "Total: 17152\n",
            "Correct: 7382\n",
            "Total: 17184\n",
            "Correct: 7392\n",
            "Total: 17216\n",
            "Correct: 7410\n",
            "Total: 17248\n",
            "Correct: 7424\n",
            "Total: 17280\n",
            "Correct: 7442\n",
            "Total: 17312\n",
            "Correct: 7456\n",
            "Total: 17344\n",
            "Correct: 7466\n",
            "Total: 17376\n",
            "Correct: 7487\n",
            "Total: 17408\n",
            "Correct: 7501\n",
            "Total: 17440\n",
            "Correct: 7515\n",
            "Total: 17472\n",
            "Correct: 7531\n",
            "Total: 17504\n",
            "Correct: 7540\n",
            "Total: 17536\n",
            "Correct: 7558\n",
            "Total: 17568\n",
            "Correct: 7573\n",
            "Total: 17600\n",
            "Correct: 7586\n",
            "Total: 17632\n",
            "Correct: 7598\n",
            "Total: 17664\n",
            "Correct: 7607\n",
            "Total: 17696\n",
            "Correct: 7620\n",
            "Total: 17728\n",
            "Correct: 7633\n",
            "Total: 17760\n",
            "Correct: 7649\n",
            "Total: 17792\n",
            "Correct: 7663\n",
            "Total: 17824\n",
            "Correct: 7681\n",
            "Total: 17856\n",
            "Correct: 7694\n",
            "Total: 17888\n",
            "Correct: 7704\n",
            "Total: 17920\n",
            "Correct: 7717\n",
            "Total: 17952\n",
            "Correct: 7729\n",
            "Total: 17984\n",
            "Correct: 7743\n",
            "Total: 18016\n",
            "Correct: 7756\n",
            "Total: 18048\n",
            "Correct: 7774\n",
            "Total: 18080\n",
            "Correct: 7794\n",
            "Total: 18112\n",
            "Correct: 7808\n",
            "Total: 18144\n",
            "Correct: 7821\n",
            "Total: 18176\n",
            "Correct: 7834\n",
            "Total: 18208\n",
            "Correct: 7844\n",
            "Total: 18240\n",
            "Correct: 7856\n",
            "Total: 18272\n",
            "Correct: 7874\n",
            "Total: 18304\n",
            "Correct: 7885\n",
            "Total: 18336\n",
            "Correct: 7904\n",
            "Total: 18368\n",
            "Correct: 7917\n",
            "Total: 18400\n",
            "Correct: 7935\n",
            "Total: 18432\n",
            "Correct: 7952\n",
            "Total: 18464\n",
            "Correct: 7963\n",
            "Total: 18496\n",
            "Correct: 7979\n",
            "Total: 18528\n",
            "Correct: 7988\n",
            "Total: 18560\n",
            "Correct: 8003\n",
            "Total: 18592\n",
            "Correct: 8018\n",
            "Total: 18624\n",
            "Correct: 8034\n",
            "Total: 18656\n",
            "Correct: 8050\n",
            "Total: 18688\n",
            "Correct: 8065\n",
            "Total: 18720\n",
            "Correct: 8078\n",
            "Total: 18752\n",
            "Correct: 8090\n",
            "Total: 18784\n",
            "Correct: 8099\n",
            "Total: 18816\n",
            "Correct: 8110\n",
            "Total: 18848\n",
            "Correct: 8123\n",
            "Total: 18880\n",
            "Correct: 8137\n",
            "Total: 18912\n",
            "Correct: 8151\n",
            "Total: 18944\n",
            "Correct: 8165\n",
            "Total: 18976\n",
            "Correct: 8179\n",
            "Total: 19008\n",
            "Correct: 8192\n",
            "Total: 19040\n",
            "Correct: 8205\n",
            "Total: 19072\n",
            "Correct: 8219\n",
            "Total: 19104\n",
            "Correct: 8238\n",
            "Total: 19136\n",
            "Correct: 8252\n",
            "Total: 19168\n",
            "Correct: 8264\n",
            "Total: 19200\n",
            "Correct: 8275\n",
            "Total: 19232\n",
            "Correct: 8290\n",
            "Total: 19264\n",
            "Correct: 8303\n",
            "Total: 19296\n",
            "Correct: 8315\n",
            "Total: 19328\n",
            "Correct: 8325\n",
            "Total: 19360\n",
            "Correct: 8334\n",
            "Total: 19392\n",
            "Correct: 8347\n",
            "Total: 19424\n",
            "Correct: 8363\n",
            "Total: 19456\n",
            "Correct: 8380\n",
            "Total: 19488\n",
            "Correct: 8398\n",
            "Total: 19520\n",
            "Correct: 8410\n",
            "Total: 19552\n",
            "Correct: 8426\n",
            "Total: 19584\n",
            "Correct: 8441\n",
            "Total: 19616\n",
            "Correct: 8452\n",
            "Total: 19648\n",
            "Correct: 8457\n",
            "Total: 19680\n",
            "Correct: 8477\n",
            "Total: 19712\n",
            "Correct: 8490\n",
            "Total: 19744\n",
            "Correct: 8506\n",
            "Total: 19776\n",
            "Correct: 8521\n",
            "Total: 19808\n",
            "Correct: 8537\n",
            "Total: 19840\n",
            "Correct: 8548\n",
            "Total: 19872\n",
            "Correct: 8560\n",
            "Total: 19904\n",
            "Correct: 8576\n",
            "Total: 19936\n",
            "Correct: 8589\n",
            "Total: 19968\n",
            "Correct: 8604\n",
            "Total: 20000\n",
            "Correct: 8621\n",
            "Total: 20032\n",
            "Correct: 8634\n",
            "Total: 20064\n",
            "Correct: 8644\n",
            "Total: 20096\n",
            "Correct: 8655\n",
            "Total: 20128\n",
            "Correct: 8668\n",
            "Total: 20160\n",
            "Correct: 8687\n",
            "Total: 20192\n",
            "Correct: 8708\n",
            "Total: 20224\n",
            "Correct: 8721\n",
            "Total: 20256\n",
            "Correct: 8737\n",
            "Total: 20288\n",
            "Correct: 8755\n",
            "Total: 20320\n",
            "Correct: 8769\n",
            "Total: 20352\n",
            "Correct: 8783\n",
            "Total: 20384\n",
            "Correct: 8796\n",
            "Total: 20416\n",
            "Correct: 8811\n",
            "Total: 20448\n",
            "Correct: 8824\n",
            "Total: 20480\n",
            "Correct: 8835\n",
            "Total: 20512\n",
            "Correct: 8848\n",
            "Total: 20544\n",
            "Correct: 8862\n",
            "Total: 20576\n",
            "Correct: 8877\n",
            "Total: 20608\n",
            "Correct: 8892\n",
            "Total: 20640\n",
            "Correct: 8905\n",
            "Total: 20672\n",
            "Correct: 8916\n",
            "Total: 20704\n",
            "Correct: 8927\n",
            "Total: 20736\n",
            "Correct: 8939\n",
            "Total: 20768\n",
            "Correct: 8953\n",
            "Total: 20800\n",
            "Correct: 8973\n",
            "Total: 20832\n",
            "Correct: 8986\n",
            "Total: 20864\n",
            "Correct: 8998\n",
            "Total: 20896\n",
            "Correct: 9009\n",
            "Total: 20928\n",
            "Correct: 9020\n",
            "Total: 20960\n",
            "Correct: 9034\n",
            "Total: 20992\n",
            "Correct: 9044\n",
            "Total: 21024\n",
            "Correct: 9060\n",
            "Total: 21056\n",
            "Correct: 9074\n",
            "Total: 21088\n",
            "Correct: 9084\n",
            "Total: 21120\n",
            "Correct: 9097\n",
            "Total: 21152\n",
            "Correct: 9112\n",
            "Total: 21184\n",
            "Correct: 9128\n",
            "Total: 21216\n",
            "Correct: 9146\n",
            "Total: 21248\n",
            "Correct: 9161\n",
            "Total: 21280\n",
            "Correct: 9175\n",
            "Total: 21312\n",
            "Correct: 9191\n",
            "Total: 21344\n",
            "Correct: 9207\n",
            "Total: 21376\n",
            "Correct: 9221\n",
            "Total: 21408\n",
            "Correct: 9236\n",
            "Total: 21440\n",
            "Correct: 9250\n",
            "Total: 21472\n",
            "Correct: 9268\n",
            "Total: 21504\n",
            "Correct: 9285\n",
            "Total: 21536\n",
            "Correct: 9298\n",
            "Total: 21568\n",
            "Correct: 9310\n",
            "Total: 21600\n",
            "Correct: 9325\n",
            "Total: 21632\n",
            "Correct: 9344\n",
            "Total: 21664\n",
            "Correct: 9356\n",
            "Total: 21696\n",
            "Correct: 9370\n",
            "Total: 21728\n",
            "Correct: 9378\n",
            "Total: 21760\n",
            "Correct: 9388\n",
            "Total: 21792\n",
            "Correct: 9402\n",
            "Total: 21824\n",
            "Correct: 9418\n",
            "Total: 21856\n",
            "Correct: 9431\n",
            "Total: 21888\n",
            "Correct: 9445\n",
            "Total: 21920\n",
            "Correct: 9456\n",
            "Total: 21952\n",
            "Correct: 9470\n",
            "Total: 21984\n",
            "Correct: 9482\n",
            "Total: 22016\n",
            "Correct: 9494\n",
            "Total: 22048\n",
            "Correct: 9509\n",
            "Total: 22080\n",
            "Correct: 9522\n",
            "Total: 22112\n",
            "Correct: 9538\n",
            "Total: 22144\n",
            "Correct: 9555\n",
            "Total: 22176\n",
            "Correct: 9565\n",
            "Total: 22208\n",
            "Correct: 9575\n",
            "Total: 22240\n",
            "Correct: 9588\n",
            "Total: 22272\n",
            "Correct: 9602\n",
            "Total: 22304\n",
            "Correct: 9615\n",
            "Total: 22336\n",
            "Correct: 9631\n",
            "Total: 22368\n",
            "Correct: 9644\n",
            "Total: 22400\n",
            "Correct: 9663\n",
            "Total: 22432\n",
            "Correct: 9677\n",
            "Total: 22464\n",
            "Correct: 9693\n",
            "Total: 22496\n",
            "Correct: 9704\n",
            "Total: 22528\n",
            "Correct: 9711\n",
            "Total: 22544\n",
            "Test Accuracy: 43.08%\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        data, labels = batch\n",
        "        outputs = maml_rnn(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        # print(\"Predicted:\", predicted)\n",
        "        # print(\"Labels: \", labels)\n",
        "\n",
        "        batch_size = labels.size(0)\n",
        "        predicted = predicted[:batch_size]\n",
        "\n",
        "        # Size of prediction and labels must be equal\n",
        "        if predicted.size(0) == labels.size(0):\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "        print(f\"Correct: {correct}\")\n",
        "        print(f\"Total: {total}\")\n",
        "\n",
        "accuracy = correct / total if total != 0 else 0.0\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "KDDTest+_Binary_Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
